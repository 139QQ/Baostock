# 4. 性能优化策略

## ⚡ 性能优化概述

基速基金量化分析平台作为数据密集型应用，性能优化是确保用户体验和系统可扩展性的关键。本章节详细说明从客户端到服务端的全方位性能优化策略和具体实施方案。

### 4.1 性能目标和指标

#### 4.1.1 核心性能指标

```yaml
performance_targets:
  # 前端性能指标
  frontend:
    # 页面加载时间
    page_load_time:
      homepage: "<= 2s"
      detail_page: "<= 1s"
      search_results: "<= 1.5s"

    # 交互响应时间
    interaction_response:
      button_click: "<= 100ms"
      form_submit: "<= 200ms"
      data_filter: "<= 300ms"

    # 资源使用
    resource_usage:
      memory_usage: "<= 200MB (mobile)"
      bundle_size: "<= 5MB (compressed)"
      cpu_usage: "<= 70% (normal load)"

  # 后端性能指标
  backend:
    # API响应时间
    api_response_time:
      simple_query: "<= 200ms"
      complex_query: "<= 1s"
      data_analysis: "<= 3s"
      batch_operation: "<= 10s"

    # 并发性能
    concurrency:
      concurrent_users: ">= 1000"
      requests_per_second: ">= 500"
      database_connections: ">= 100"

    # 系统资源
    system_resources:
      cpu_usage: "<= 80%"
      memory_usage: "<= 85%"
      disk_io_wait: "<= 20%"
```

#### 4.1.2 性能监控体系

```dart
// performance_monitor.dart - Flutter性能监控
class PerformanceMonitor {
  static final PerformanceMonitor _instance = PerformanceMonitor._internal();
  factory PerformanceMonitor() => _instance;
  PerformanceMonitor._internal();

  final Map<String, DateTime> _startTimes = {};
  final Map<String, List<Duration>> _performanceData = {};

  // 开始性能追踪
  void startTracking(String operation) {
    _startTimes[operation] = DateTime.now();
  }

  // 结束性能追踪并记录
  Duration endTracking(String operation) {
    final startTime = _startTimes[operation];
    if (startTime == null) return Duration.zero;

    final duration = DateTime.now().difference(startTime);
    _recordPerformance(operation, duration);
    _startTimes.remove(operation);

    // 性能预警
    _checkPerformanceThreshold(operation, duration);

    return duration;
  }

  void _recordPerformance(String operation, Duration duration) {
    _performanceData[operation] ??= [];
    _performanceData[operation]!.add(duration);

    // 保持最近100次记录
    if (_performanceData[operation]!.length > 100) {
      _performanceData[operation]!.removeAt(0);
    }
  }

  void _checkPerformanceThreshold(String operation, Duration duration) {
    final thresholds = {
      'page_load': Duration(seconds: 2),
      'api_call': Duration(milliseconds: 500),
      'chart_render': Duration(milliseconds: 1000),
    };

    final threshold = thresholds[operation];
    if (threshold != null && duration > threshold) {
      _sendPerformanceAlert(operation, duration, threshold);
    }
  }

  void _sendPerformanceAlert(String operation, Duration actual, Duration threshold) {
    // 发送性能预警到监控系统
    Logger().warning(
      'Performance Alert: $operation took ${actual.inMilliseconds}ms '
      '(threshold: ${threshold.inMilliseconds}ms)'
    );
  }

  // 获取性能统计
  PerformanceStats getStats(String operation) {
    final data = _performanceData[operation] ?? [];
    if (data.isEmpty) return PerformanceStats.empty();

    final sortedData = List<Duration>.from(data)..sort();
    final total = data.fold(Duration.zero, (sum, d) => sum + d);

    return PerformanceStats(
      count: data.length,
      average: total ~/ data.length,
      median: sortedData[data.length ~/ 2],
      p95: sortedData[(data.length * 0.95).floor()],
      p99: sortedData[(data.length * 0.99).floor()],
    );
  }
}

class PerformanceStats {
  final int count;
  final Duration average;
  final Duration median;
  final Duration p95;
  final Duration p99;

  PerformanceStats({
    required this.count,
    required this.average,
    required this.median,
    required this.p95,
    required this.p99,
  });

  static PerformanceStats empty() {
    return PerformanceStats(
      count: 0,
      average: Duration.zero,
      median: Duration.zero,
      p95: Duration.zero,
      p99: Duration.zero,
    );
  }
}
```

### 4.2 前端性能优化

#### 4.2.1 应用启动优化

**Flutter启动性能优化**：
```dart
// main.dart - 应用启动优化
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';

Future<void> main() async {
  // 确保Flutter绑定初始化
  WidgetsFlutterBinding.ensureInitialized();

  // 预加载关键资源
  await _preloadCriticalResources();

  // 设置系统UI
  await _setupSystemUI();

  // 启动应用
  runApp(JisuApp());
}

Future<void> _preloadCriticalResources() async {
  // 并行预加载关键资源
  final futures = [
    _preloadFonts(),
    _preloadImages(),
    _preloadConfigurations(),
  ];

  await Future.wait(futures);
}

Future<void> _preloadFonts() async {
  // 预加载Google Fonts
  await GoogleFonts.pendingFonts([
    GoogleFonts.inter(),
    GoogleFonts.roboto(),
  ]);
}

Future<void> _preloadImages() async {
  // 预加载关键图片资源
  final imageProvider = AssetImage('assets/images/logo.png');
  await precacheImage(imageProvider, context);
}

Future<void> _preloadConfigurations() async {
  // 预加载应用配置
  await ConfigManager.loadConfig();
}

Future<void> _setupSystemUI() async {
  // 设置状态栏和导航栏
  SystemChrome.setSystemUIOverlayStyle(
    SystemUiOverlayStyle.dark.copyWith(
      statusBarColor: Colors.transparent,
    ),
  );

  // 设置首选设备方向
  await SystemChrome.setPreferredOrientations([
    DeviceOrientation.portraitUp,
    DeviceOrientation.portraitDown,
  ]);
}
```

**延迟加载策略**：
```dart
// deferred_loading.dart - 延迟加载实现
class DeferredLoader {
  static bool _analysisModuleLoaded = false;
  static bool _portfolioModuleLoaded = false;

  // 延迟加载分析模块
  static Future<void> loadAnalysisModule() async {
    if (_analysisModuleLoaded) return;

    final monitor = PerformanceMonitor();
    monitor.startTracking('load_analysis_module');

    await Future.delayed(Duration(milliseconds: 100));
    await _loadLibrary('analysis_module');

    _analysisModuleLoaded = true;
    monitor.endTracking('load_analysis_module');
  }

  // 延迟加载投资组合模块
  static Future<void> loadPortfolioModule() async {
    if (_portfolioModuleLoaded) return;

    final monitor = PerformanceMonitor();
    monitor.startTracking('load_portfolio_module');

    await _loadLibrary('portfolio_module');
    _portfolioModuleLoaded = true;

    monitor.endTracking('load_portfolio_module');
  }

  static Future<void> _loadLibrary(String libraryName) async {
    // 实际的库加载逻辑
    // 这里可以配合Flutter的deferred imports
    await Future.delayed(Duration(milliseconds: 50));
  }
}

// 使用示例
class AnalysisPage extends StatefulWidget {
  @override
  _AnalysisPageState createState() => _AnalysisPageState();
}

class _AnalysisPageState extends State<AnalysisPage> {
  bool _moduleLoaded = false;

  @override
  void initState() {
    super.initState();
    _loadModule();
  }

  Future<void> _loadModule() async {
    await DeferredLoader.loadAnalysisModule();
    setState(() {
      _moduleLoaded = true;
    });
  }

  @override
  Widget build(BuildContext context) {
    if (!_moduleLoaded) {
      return Scaffold(
        body: Center(
          child: Column(
            mainAxisAlignment: MainAxisAlignment.center,
            children: [
              CircularProgressIndicator(),
              SizedBox(height: 16),
              Text('正在加载分析工具...'),
            ],
          ),
        ),
      );
    }

    return AnalysisContent();
  }
}
```

#### 4.2.2 界面渲染优化

**Widget性能优化**：
```dart
// performance_widgets.dart - 高性能Widget实现
class OptimizedFundList extends StatelessWidget {
  final List<Fund> funds;
  final ScrollController scrollController;

  const OptimizedFundList({
    super.key,
    required this.funds,
    required this.scrollController,
  });

  @override
  Widget build(BuildContext context) {
    return ListView.builder(
      controller: scrollController,
      itemCount: funds.length,
      // 使用缓存 extent 提升滚动性能
      cacheExtent: 500,
      itemBuilder: (context, index) {
        return _buildOptimizedFundItem(funds[index], index);
      },
    );
  }

  Widget _buildOptimizedFundItem(Fund fund, int index) {
    // 使用 AutomaticKeepAliveClientMixin 保持状态
    return _FundItem(
      key: ValueKey(fund.code),
      fund: fund,
    );
  }
}

class _FundItem extends StatefulWidget {
  final Fund fund;

  const _FundItem({
    super.key,
    required this.fund,
  });

  @override
  State<_FundItem> createState() => _FundItemState();
}

class _FundItemState extends State<_FundItem>
    with AutomaticKeepAliveClientMixin {

  @override
  bool get wantKeepAlive => true;

  @override
  Widget build(BuildContext context) {
    super.build(context); // 必须调用以保持状态

    return RepaintBoundary(
      child: Card(
        margin: EdgeInsets.symmetric(horizontal: 16, vertical: 4),
        child: Padding(
          padding: EdgeInsets.all(16),
          child: Column(
            crossAxisAlignment: CrossAxisAlignment.start,
            children: [
              _buildFundHeader(),
              SizedBox(height: 8),
              _buildFundMetrics(),
            ],
          ),
        ),
      ),
    );
  }

  Widget _buildFundHeader() {
    return Row(
      children: [
        Expanded(
          child: Column(
            crossAxisAlignment: CrossAxisAlignment.start,
            children: [
              Text(
                widget.fund.name,
                style: TextStyle(
                  fontSize: 16,
                  fontWeight: FontWeight.w600,
                ),
                maxLines: 1,
                overflow: TextOverflow.ellipsis,
              ),
              SizedBox(height: 2),
              Text(
                widget.fund.code,
                style: TextStyle(
                  fontSize: 12,
                  color: Colors.grey[600],
                ),
              ),
            ],
          ),
        ),
        Icon(
          widget.fund.isFavorite ? Icons.favorite : Icons.favorite_border,
          color: widget.fund.isFavorite ? Colors.red : Colors.grey,
        ),
      ],
    );
  }

  Widget _buildFundMetrics() {
    return Row(
      mainAxisAlignment: MainAxisAlignment.spaceBetween,
      children: [
        _buildMetricItem('最新净值', widget.fund.latestNav?.toStringAsFixed(4)),
        _buildMetricItem(
          '日涨幅',
          '${widget.fund.dailyChange?.toStringAsFixed(2)}%',
          widget.fund.dailyChange != null && widget.fund.dailyChange! >= 0
              ? Colors.green
              : Colors.red,
        ),
      ],
    );
  }

  Widget _buildMetricItem(String label, String value, [Color? valueColor]) {
    return Column(
      crossAxisAlignment: CrossAxisAlignment.start,
      children: [
        Text(
          label,
          style: TextStyle(
            fontSize: 11,
            color: Colors.grey[600],
          ),
        ),
        SizedBox(height: 2),
        Text(
          value,
          style: TextStyle(
            fontSize: 14,
            fontWeight: FontWeight.w600,
            color: valueColor,
          ),
        ),
      ],
    );
  }
}
```

**图表渲染优化**：
```dart
// optimized_chart.dart - 高性能图表实现
class OptimizedChart extends StatefulWidget {
  final List<ChartData> data;
  final ChartConfig config;

  const OptimizedChart({
    super.key,
    required this.data,
    required this.config,
  });

  @override
  State<OptimizedChart> createState() => _OptimizedChartState();
}

class _OptimizedChartState extends State<OptimizedChart> {
  final GlobalKey _chartKey = GlobalKey();

  @override
  Widget build(BuildContext context) {
    return RepaintBoundary(
      key: _chartKey,
      child: CustomPaint(
        painter: OptimizedChartPainter(
          data: widget.data,
          config: widget.config,
        ),
        size: Size.infinite,
      ),
    );
  }
}

class OptimizedChartPainter extends CustomPainter {
  final List<ChartData> data;
  final ChartConfig config;

  OptimizedChartPainter({
    required this.data,
    required this.config,
  });

  @override
  void paint(Canvas canvas, Size size) {
    final monitor = PerformanceMonitor();
    monitor.startTracking('chart_render');

    _drawBackground(canvas, size);
    _drawGrid(canvas, size);
    _drawData(canvas, size);
    _drawAxes(canvas, size);

    monitor.endTracking('chart_render');
  }

  void _drawBackground(Canvas canvas, Size size) {
    final paint = Paint()
      ..color = config.backgroundColor
      ..style = PaintingStyle.fill;

    canvas.drawRect(Offset.zero & size, paint);
  }

  void _drawGrid(Canvas canvas, Size size) {
    if (!config.showGrid) return;

    final gridPaint = Paint()
      ..color = config.gridColor
      ..strokeWidth = 0.5
      ..style = PaintingStyle.stroke;

    // 绘制水平网格线
    for (int i = 0; i <= config.horizontalLines; i++) {
      final y = (size.height / config.horizontalLines) * i;
      canvas.drawLine(
        Offset(0, y),
        Offset(size.width, y),
        gridPaint,
      );
    }

    // 绘制垂直网格线
    for (int i = 0; i <= config.verticalLines; i++) {
      final x = (size.width / config.verticalLines) * i;
      canvas.drawLine(
        Offset(x, 0),
        Offset(x, size.height),
        gridPaint,
      );
    }
  }

  void _drawData(Canvas canvas, Size size) {
    if (data.isEmpty) return;

    final path = Path();
    final linePaint = Paint()
      ..color = config.lineColor
      ..strokeWidth = config.lineWidth
      ..style = PaintingStyle.stroke
      ..strokeCap = StrokeCap.round;

    // 数据点绘制优化 - 只绘制可见区域的数据点
    final visibleData = _getVisibleData(size);
    if (visibleData.length < 2) return;

    final firstPoint = _mapDataToPoint(visibleData[0], size);
    path.moveTo(firstPoint.dx, firstPoint.dy);

    for (int i = 1; i < visibleData.length; i++) {
      final point = _mapDataToPoint(visibleData[i], size);
      path.lineTo(point.dx, point.dy);
    }

    canvas.drawPath(path, linePaint);

    // 绘制数据点
    if (config.showDataPoints) {
      _drawDataPoints(canvas, size, visibleData);
    }
  }

  List<ChartData> _getVisibleData(Size size) {
    // 只返回可见区域的数据点
    final startIndex = (config.scrollOffset * data.length / config.totalWidth).floor();
    final endIndex = ((config.scrollOffset + size.width) * data.length / config.totalWidth).ceil();

    return data.sublist(
      startIndex.clamp(0, data.length - 1),
      endIndex.clamp(0, data.length),
    );
  }

  Offset _mapDataToPoint(ChartData data, Size size) {
    final x = (data.x - config.minX) / (config.maxX - config.minX) * size.width;
    final y = size.height - (data.y - config.minY) / (config.maxY - config.minY) * size.height;
    return Offset(x, y);
  }

  void _drawDataPoints(Canvas canvas, Size size, List<ChartData> visibleData) {
    final pointPaint = Paint()
      ..color = config.pointColor
      ..style = PaintingStyle.fill;

    for (final data in visibleData) {
      final point = _mapDataToPoint(data, size);
      canvas.drawCircle(point, config.pointRadius, pointPaint);
    }
  }

  void _drawAxes(Canvas canvas, Size size) {
    // 绘制坐标轴
    final axisPaint = Paint()
      ..color = config.axisColor
      ..strokeWidth = 1
      ..style = PaintingStyle.stroke;

    // X轴
    canvas.drawLine(
      Offset(0, size.height),
      Offset(size.width, size.height),
      axisPaint,
    );

    // Y轴
    canvas.drawLine(
      Offset(0, 0),
      Offset(0, size.height),
      axisPaint,
    );
  }

  @override
  bool shouldRepaint(OptimizedChartPainter oldDelegate) {
    return oldDelegate.data != data || oldDelegate.config != config;
  }
}
```

#### 4.2.3 内存管理优化

**内存监控和管理**：
```dart
// memory_manager.dart - 内存管理器
class MemoryManager {
  static final MemoryManager _instance = MemoryManager._internal();
  factory MemoryManager() => _instance;
  MemoryManager._internal();

  Timer? _memoryMonitorTimer;
  final Map<String, DateTime> _cacheTimestamps = {};
  final int _maxCacheAge = 30 * 60 * 1000; // 30分钟

  void startMemoryMonitoring() {
    _memoryMonitorTimer = Timer.periodic(Duration(minutes: 1), (_) {
      _checkMemoryUsage();
    });
  }

  void stopMemoryMonitoring() {
    _memoryMonitorTimer?.cancel();
  }

  Future<void> _checkMemoryUsage() async {
    final info = await ProcessInfo.currentRss;
    final memoryMB = info / (1024 * 1024);

    Logger().info('Memory usage: ${memoryMB.toStringAsFixed(1)} MB');

    if (memoryMB > 180) { // 接近200MB限制
      Logger().warning('Memory usage high, triggering cleanup');
      await _performMemoryCleanup();
    }
  }

  Future<void> _performMemoryCleanup() async {
    // 清理过期缓存
    await _cleanExpiredCache();

    // 触发垃圾回收
    await _triggerGarbageCollection();

    // 通知各组件进行内存优化
    _notifyMemoryOptimization();
  }

  Future<void> _cleanExpiredCache() async {
    final now = DateTime.now();
    final expiredKeys = <String>[];

    _cacheTimestamps.forEach((key, timestamp) {
      if (now.difference(timestamp).inMilliseconds > _maxCacheAge) {
        expiredKeys.add(key);
      }
    });

    for (final key in expiredKeys) {
      _cacheTimestamps.remove(key);
      // 清理对应的缓存数据
      CacheManager.instance.remove(key);
    }

    if (expiredKeys.isNotEmpty) {
      Logger().info('Cleaned ${expiredKeys.length} expired cache items');
    }
  }

  Future<void> _triggerGarbageCollection() async {
    // Flutter没有直接的GC触发方法，但可以通过以下方式间接触发
    await Future.delayed(Duration(milliseconds: 100));

    // 创建临时对象触发GC
    List<List<int>> tempData = [];
    for (int i = 0; i < 100; i++) {
      tempData.add(List.generate(1000, (_) => i));
    }

    // 清空引用
    tempData.clear();
  }

  void _notifyMemoryOptimization() {
    // 通知各组件进行内存优化
    MemoryOptimizationEvent().broadcast();
  }

  void registerCacheItem(String key) {
    _cacheTimestamps[key] = DateTime.now();
  }

  void updateCacheTimestamp(String key) {
    if (_cacheTimestamps.containsKey(key)) {
      _cacheTimestamps[key] = DateTime.now();
    }
  }
}

// 内存优化事件
class MemoryOptimizationEvent {
  static final MemoryOptimizationEvent _instance = MemoryOptimizationEvent._internal();
  factory MemoryOptimizationEvent() => _instance;
  MemoryOptimizationEvent._internal();

  final StreamController<void> _controller = StreamController<void>.broadcast();

  Stream<void> get stream => _controller.stream;

  void broadcast() {
    _controller.add(null);
  }

  void dispose() {
    _controller.close();
  }
}
```

### 4.3 后端性能优化

#### 4.3.1 数据库性能优化

**查询优化策略**：
```python
# database/query_optimizer.py - 查询优化器
from sqlalchemy import text, and_, or_
from sqlalchemy.orm import Session, load_only, joinedload
from typing import List, Optional, Dict, Any
import asyncio

class QueryOptimizer:
    def __init__(self, db_session: Session):
        self.db = db_session

    async def get_funds_with_optimization(
        self,
        filters: Dict[str, Any] = None,
        pagination: Dict[str, int] = None,
        ordering: str = 'name'
    ) -> List[Fund]:
        """优化的基金查询"""
        query = self.db.query(Fund)

        # 使用索引优化过滤
        if filters:
            query = self._apply_filters(query, filters)

        # 优化的排序
        query = self._apply_ordering(query, ordering)

        # 分页优化
        if pagination:
            query = self._apply_pagination(query, pagination)

        # 使用只加载必要字段
        query = query.options(
            load_only(
                Fund.code, Fund.name, Fund.type, Fund.company,
                Fund.latest_nav, Fund.latest_date, Fund.risk_level
            )
        )

        # 批量预加载关联数据
        query = query.options(
            joinedload(Fund.company)
        )

        return await asyncio.get_event_loop().run_in_executor(
            None, query.all
        )

    def _apply_filters(self, query, filters: Dict[str, Any]):
        """应用过滤条件"""
        if filters.get('type'):
            query = query.filter(Fund.type == filters['type'])

        if filters.get('company'):
            query = query.filter(Fund.company.ilike(f"%{filters['company']}%"))

        if filters.get('risk_level'):
            query = query.filter(Fund.risk_level == filters['risk_level'])

        # 使用索引范围查询
        if filters.get('min_nav'):
            query = query.filter(Fund.latest_nav >= filters['min_nav'])

        if filters.get('max_nav'):
            query = query.filter(Fund.latest_nav <= filters['max_nav'])

        return query

    def _apply_ordering(self, query, ordering: str):
        """应用排序"""
        ordering_map = {
            'name': Fund.name,
            'nav': Fund.latest_nav.desc(),
            'date': Fund.latest_date.desc(),
            'company': Fund.company,
        }

        if ordering in ordering_map:
            query = query.order_by(ordering_map[ordering])

        return query

    def _apply_pagination(self, query, pagination: Dict[str, int]):
        """应用分页"""
        page = pagination.get('page', 1)
        per_page = pagination.get('per_page', 20)

        offset = (page - 1) * per_page
        query = query.offset(offset).limit(per_page)

        return query

    async def bulk_update_fund_nav_history(self, nav_data: List[Dict]):
        """批量更新基金净值历史"""
        # 使用批量插入优化
        insert_statement = text("""
            INSERT INTO fund_nav_history
            (fund_code, nav_date, nav_value, accumulated_nav, daily_change, daily_change_rate)
            VALUES (:fund_code, :nav_date, :nav_value, :accumulated_nav, :daily_change, :daily_change_rate)
            ON CONFLICT (fund_code, nav_date)
            DO UPDATE SET
                nav_value = EXCLUDED.nav_value,
                accumulated_nav = EXCLUDED.accumulated_nav,
                daily_change = EXCLUDED.daily_change,
                daily_change_rate = EXCLUDED.daily_change_rate,
                updated_at = CURRENT_TIMESTAMP
        """)

        # 分批执行，避免内存溢出
        batch_size = 1000
        for i in range(0, len(nav_data), batch_size):
            batch = nav_data[i:i + batch_size]
            await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.db.execute(insert_statement, batch)
            )

        self.db.commit()
```

**连接池优化**：
```python
# database/connection_pool.py - 连接池优化
import asyncpg
from contextlib import asynccontextmanager
from typing import AsyncGenerator

class OptimizedConnectionPool:
    def __init__(self, config: DatabaseConfig):
        self.config = config
        self.pool = None

    async def initialize(self):
        """初始化连接池"""
        self.pool = await asyncpg.create_pool(
            dsn=self.config.dsn,
            min_size=self.config.min_connections,
            max_size=self.config.max_connections,
            max_queries=self.config.max_queries_per_connection,
            max_inactive_connection_lifetime=self.config.max_inactive_lifetime,
            command_timeout=self.config.command_timeout,
            # 连接预热
            setup=self._setup_connection,
        )

    async def _setup_connection(self, connection):
        """连接预热设置"""
        # 设置会话参数
        await connection.execute("SET timezone TO 'UTC'")
        await connection.execute("SET statement_timeout = '30s'")

        # 准备常用查询
        await connection.prepare("""
            SELECT * FROM funds WHERE code = $1
        """)

        await connection.prepare("""
            SELECT * FROM fund_nav_history
            WHERE fund_code = $1 AND nav_date >= $2
            ORDER BY nav_date DESC LIMIT $3
        """)

    @asynccontextmanager
    async def get_connection(self) -> AsyncGenerator[asyncpg.Connection, None]:
        """获取数据库连接"""
        if not self.pool:
            await self.initialize()

        connection = await self.pool.acquire()
        try:
            yield connection
        finally:
            await self.pool.release(connection)

    async def execute_query(self, query: str, *args) -> list:
        """执行查询"""
        async with self.get_connection() as conn:
            return await conn.fetch(query, *args)

    async def execute_command(self, command: str, *args) -> str:
        """执行命令"""
        async with self.get_connection() as conn:
            return await conn.execute(command, *args)

    async def close(self):
        """关闭连接池"""
        if self.pool:
            await self.pool.close()

    def get_pool_stats(self) -> dict:
        """获取连接池统计信息"""
        if not self.pool:
            return {}

        return {
            'size': self.pool.get_size(),
            'idle': self.pool.get_idle_size(),
            'max_size': self.pool.get_max_size(),
        }
```

#### 4.3.2 API性能优化

**响应优化中间件**：
```python
# middleware/performance_middleware.py - 性能优化中间件
import time
import asyncio
from fastapi import Request, Response
from starlette.middleware.base import BaseHTTPMiddleware
from typing import Callable
import json

class PerformanceMiddleware(BaseHTTPMiddleware):
    def __init__(self, app, cache_manager=None):
        super().__init__(app)
        self.cache_manager = cache_manager

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        start_time = time.time()

        # 尝试从缓存获取响应
        if self.cache_manager:
            cached_response = await self._get_cached_response(request)
            if cached_response:
                return cached_response

        # 执行请求
        response = await call_next(request)

        # 计算响应时间
        process_time = time.time() - start_time

        # 添加性能头
        response.headers["X-Process-Time"] = str(process_time)

        # 缓存响应
        if self.cache_manager and self._should_cache_response(request, response):
            await self._cache_response(request, response, process_time)

        return response

    async def _get_cached_response(self, request: Request) -> Response:
        """从缓存获取响应"""
        cache_key = self._generate_cache_key(request)
        cached_data = await self.cache_manager.get(cache_key)

        if cached_data:
            response = Response(
                content=cached_data['content'],
                status_code=cached_data['status_code'],
                headers=cached_data['headers'],
                media_type=cached_data['media_type']
            )
            response.headers["X-Cache"] = "HIT"
            return response

        return None

    def _should_cache_response(self, request: Request, response: Response) -> bool:
        """判断是否应该缓存响应"""
        # 只缓存GET请求
        if request.method != "GET":
            return False

        # 只缓存成功响应
        if response.status_code != 200:
            return False

        # 检查Cache-Control头
        cache_control = response.headers.get("cache-control", "")
        if "no-cache" in cache_control or "private" in cache_control:
            return False

        return True

    async def _cache_response(
        self,
        request: Request,
        response: Response,
        process_time: float
    ):
        """缓存响应"""
        cache_key = self._generate_cache_key(request)

        # 根据响应时间设置缓存TTL
        if process_time > 1.0:  # 响应时间超过1秒，缓存更长时间
            ttl = 3600  # 1小时
        else:
            ttl = 600   # 10分钟

        cache_data = {
            'content': response.body,
            'status_code': response.status_code,
            'headers': dict(response.headers),
            'media_type': response.media_type,
        }

        await self.cache_manager.set(cache_key, cache_data, ttl=ttl)

    def _generate_cache_key(self, request: Request) -> str:
        """生成缓存键"""
        path = request.url.path
        query_params = sorted(request.query_params.items())
        query_string = "&".join([f"{k}={v}" for k, v in query_params])
        return f"{path}?{query_string}"

# 响应压缩中间件
import gzip
from fastapi.responses import JSONResponse

class CompressionMiddleware(BaseHTTPMiddleware):
    def __init__(self, app, min_size: int = 1024):
        super().__init__(app)
        self.min_size = min_size

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        response = await call_next(request)

        # 检查是否支持压缩
        if (
            "gzip" not in request.headers.get("accept-encoding", "") or
            len(response.body) < self.min_size or
            response.headers.get("content-encoding") is not None
        ):
            return response

        # 压缩响应内容
        compressed_body = gzip.compress(response.body)

        # 创建压缩后的响应
        compressed_response = JSONResponse(
            content=compressed_body,
            status_code=response.status_code,
            headers=dict(response.headers)
        )
        compressed_response.headers["content-encoding"] = "gzip"
        compressed_response.headers["content-length"] = str(len(compressed_body))

        return compressed_response
```

### 4.4 缓存策略优化

#### 4.4.1 智能缓存策略

**缓存预热和失效策略**：
```python
# cache/smart_cache.py - 智能缓存管理器
import asyncio
import hashlib
from typing import Any, Dict, List, Optional, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass

@dataclass
class CacheConfig:
    ttl: int = 3600  # 默认TTL (秒)
    max_size: int = 10000  # 最大缓存项数
    refresh_threshold: float = 0.8  # 刷新阈值 (TTL的80%时触发刷新)
    compression_threshold: int = 1024  # 压缩阈值 (字节)

class SmartCacheManager:
    def __init__(self, redis_client, config: CacheConfig = None):
        self.redis = redis_client
        self.config = config or CacheConfig()
        self._background_tasks = set()
        self._access_stats = {}  # 访问统计
        self._hot_keys = set()   # 热点键

    async def get(self, key: str, refresh_callback: Callable = None) -> Optional[Any]:
        """智能获取缓存"""
        # 更新访问统计
        await self._update_access_stats(key)

        # 获取缓存数据和元数据
        cache_data = await self._get_cache_with_metadata(key)
        if not cache_data:
            return None

        data, metadata = cache_data
        now = datetime.utcnow()

        # 检查是否需要后台刷新
        if refresh_callback and self._should_refresh(metadata, now):
            await self._schedule_background_refresh(key, refresh_callback)

        return data

    async def set(
        self,
        key: str,
        value: Any,
        ttl: Optional[int] = None,
        tags: List[str] = None
    ) -> bool:
        """智能设置缓存"""
        ttl = ttl or self.config.ttl
        now = datetime.utcnow()

        # 准备缓存元数据
        metadata = {
            'created_at': now.isoformat(),
            'expires_at': (now + timedelta(seconds=ttl)).isoformat(),
            'access_count': 0,
            'last_accessed': now.isoformat(),
            'tags': tags or [],
            'size': self._calculate_size(value),
        }

        # 数据压缩
        compressed_value = await self._compress_if_needed(value)

        cache_item = {
            'data': compressed_value,
            'metadata': metadata,
            'compressed': metadata['size'] > self.config.compression_threshold
        }

        try:
            # 使用Redis pipeline提高性能
            async with self.redis.pipeline() as pipe:
                # 设置主缓存
                await pipe.setex(
                    f"cache:{key}",
                    ttl,
                    json.dumps(cache_item, default=str)
                )

                # 设置访问统计
                await pipe.hset(
                    f"stats:{key}",
                    mapping={
                        'access_count': 0,
                        'last_accessed': now.isoformat(),
                    }
                )

                # 设置标签索引
                if tags:
                    for tag in tags:
                        await pipe.sadd(f"tag:{tag}", key)

                await pipe.execute()

            return True
        except Exception as e:
            logger.error(f"Cache set error for key {key}: {e}")
            return False

    async def _get_cache_with_metadata(self, key: str) -> Optional[tuple]:
        """获取缓存数据和元数据"""
        try:
            cache_item = await self.redis.get(f"cache:{key}")
            if not cache_item:
                return None

            item_data = json.loads(cache_item)
            data = item_data['data']
            metadata = item_data['metadata']

            # 解压缩数据
            if item_data.get('compressed', False):
                data = await self._decompress_data(data)

            return data, metadata
        except Exception as e:
            logger.error(f"Cache get error for key {key}: {e}")
            return None

    def _should_refresh(self, metadata: Dict, now: datetime) -> bool:
        """判断是否需要后台刷新"""
        expires_at = datetime.fromisoformat(metadata['expires_at'])
        created_at = datetime.fromisoformat(metadata['created_at'])
        ttl = (expires_at - created_at).total_seconds()
        refresh_time = created_at + timedelta(seconds=ttl * self.config.refresh_threshold)

        return now >= refresh_time

    async def _schedule_background_refresh(self, key: str, refresh_callback: Callable):
        """调度后台刷新任务"""
        if key in self._background_tasks:
            return  # 避免重复刷新

        task = asyncio.create_task(self._background_refresh(key, refresh_callback))
        self._background_tasks.add(key)
        task.add_done_callback(lambda _: self._background_tasks.discard(key))

    async def _background_refresh(self, key: str, refresh_callback: Callable):
        """后台刷新缓存"""
        try:
            # 延迟执行，避免与当前请求冲突
            await asyncio.sleep(1)

            # 执行刷新回调
            new_value = await refresh_callback()

            # 更新缓存
            if new_value is not None:
                await self.set(key, new_value)
                logger.info(f"Background refresh completed for key: {key}")

        except Exception as e:
            logger.error(f"Background refresh failed for key {key}: {e}")

    async def _update_access_stats(self, key: str):
        """更新访问统计"""
        try:
            now = datetime.utcnow()
            async with self.redis.pipeline() as pipe:
                # 更新访问计数
                await pipe.hincrby(f"stats:{key}", 'access_count', 1)
                await pipe.hset(f"stats:{key}", 'last_accessed', now.isoformat())

                # 更新热点键统计
                await pipe.zincrby('hot_keys', 1, key)

                await pipe.execute()

            # 定期清理热点键统计
            await self._cleanup_hot_keys()

        except Exception as e:
            logger.error(f"Access stats update error for key {key}: {e}")

    async def _cleanup_hot_keys(self):
        """清理热点键统计"""
        # 每小时执行一次清理
        if not hasattr(self, '_last_cleanup') or \
           datetime.utcnow() - self._last_cleanup > timedelta(hours=1):

            # 保留前1000个热点键
            await self.redis.zremrangebyrank('hot_keys', 0, -1001)
            self._last_cleanup = datetime.utcnow()

    async def _compress_if_needed(self, value: Any) -> Any:
        """根据需要压缩数据"""
        size = self._calculate_size(value)
        if size > self.config.compression_threshold:
            # 实现压缩逻辑
            return self._compress_data(value)
        return value

    def _calculate_size(self, value: Any) -> int:
        """计算数据大小"""
        return len(json.dumps(value, default=str).encode('utf-8'))

    async def _compress_data(self, data: Any) -> bytes:
        """压缩数据"""
        import gzip
        json_str = json.dumps(data, default=str)
        return gzip.compress(json_str.encode('utf-8'))

    async def _decompress_data(self, compressed_data: bytes) -> Any:
        """解压缩数据"""
        import gzip
        decompressed = gzip.decompress(compressed_data)
        return json.loads(decompressed.decode('utf-8'))

    async def invalidate_by_tags(self, tags: List[str]) -> int:
        """按标签失效缓存"""
        keys_to_invalidate = set()

        for tag in tags:
            # 获取标签下的所有键
            tagged_keys = await self.redis.smembers(f"tag:{tag}")
            keys_to_invalidate.update(tagged_keys)

        # 批量删除
        if keys_to_invalidate:
            keys = [f"cache:{key}" for key in keys_to_invalidate]
            await self.redis.delete(*keys)

            # 删除统计信息
            stats_keys = [f"stats:{key}" for key in keys_to_invalidate]
            await self.redis.delete(*stats_keys)

        return len(keys_to_invalidate)

    async def get_cache_stats(self) -> Dict[str, Any]:
        """获取缓存统计信息"""
        try:
            # 获取Redis基础信息
            info = await self.redis.info()

            # 获取热点键统计
            hot_keys = await self.redis.zrevrange('hot_keys', 0, 9, withscores=True)

            return {
                'redis_memory_usage': info.get('used_memory', 0),
                'redis_connected_clients': info.get('connected_clients', 0),
                'redis_total_commands': info.get('total_commands_processed', 0),
                'hot_keys': [{'key': key, 'score': score} for key, score in hot_keys],
                'background_tasks_count': len(self._background_tasks),
            }
        except Exception as e:
            logger.error(f"Cache stats error: {e}")
            return {}
```

---

*本章节详细说明了基速平台的性能优化策略，包括前端优化、后端优化、数据库优化、缓存优化等各个层面的具体实施方案*