# 6. éƒ¨ç½²æ¶æ„

## ğŸš€ éƒ¨ç½²æ¶æ„æ¦‚è¿°

åŸºé€ŸåŸºé‡‘é‡åŒ–åˆ†æå¹³å°é‡‡ç”¨ç°ä»£åŒ–çš„äº‘åŸç”Ÿéƒ¨ç½²æ¶æ„ï¼Œæ”¯æŒå¤šç¯å¢ƒéƒ¨ç½²ã€è‡ªåŠ¨åŒ–CI/CDæµæ°´çº¿ã€å®¹å™¨åŒ–ç®¡ç†å’Œå¼¹æ€§æ‰©å±•ã€‚æœ¬ç« èŠ‚è¯¦ç»†è¯´æ˜å¹³å°çš„éƒ¨ç½²æ¶æ„è®¾è®¡ã€ç¯å¢ƒé…ç½®ã€ç›‘æ§è¿ç»´ç­‰å„ä¸ªæ–¹é¢ã€‚

### 6.1 éƒ¨ç½²æ¶æ„ç›®æ ‡

#### 6.1.1 æ ¸å¿ƒéƒ¨ç½²ç›®æ ‡

**é«˜å¯ç”¨æ€§ (High Availability)**
- ç³»ç»Ÿå¯ç”¨æ€§è¾¾åˆ°99.9%ä»¥ä¸Š
- æ”¯æŒæ•…éšœè‡ªåŠ¨åˆ‡æ¢å’Œæ¢å¤
- å¤šåŒºåŸŸéƒ¨ç½²é¿å…å•ç‚¹æ•…éšœ
- è´Ÿè½½å‡è¡¡ç¡®ä¿æœåŠ¡è¿ç»­æ€§

**å¯æ‰©å±•æ€§ (Scalability)**
- æ”¯æŒæ°´å¹³æ‰©å±•åº”å¯¹ç”¨æˆ·å¢é•¿
- è‡ªåŠ¨æ‰©ç¼©å®¹æœºåˆ¶ä¼˜åŒ–èµ„æºä½¿ç”¨
- å¾®æœåŠ¡æ¶æ„æ”¯æŒç‹¬ç«‹æ‰©å±•
- æ— ç¼å‡çº§å’Œç‰ˆæœ¬ç®¡ç†

**å®‰å…¨æ€§ (Security)**
- ç”Ÿäº§ç¯å¢ƒå…¨é¢çš„å®‰å…¨é˜²æŠ¤
- ç½‘ç»œéš”ç¦»å’Œè®¿é—®æ§åˆ¶
- æ•°æ®åŠ å¯†å’Œå®‰å…¨ä¼ è¾“
- å®‰å…¨ç›‘æ§å’Œå¨èƒæ£€æµ‹

**è¿ç»´æ•ˆç‡ (Operational Efficiency)**
- è‡ªåŠ¨åŒ–éƒ¨ç½²å’Œè¿ç»´æµç¨‹
- å®Œå–„çš„ç›‘æ§å‘Šè­¦ä½“ç³»
- å¿«é€Ÿçš„é—®é¢˜å®šä½å’Œæ¢å¤
- æ ‡å‡†åŒ–çš„è¿ç»´æ“ä½œ

#### 6.1.2 éƒ¨ç½²ç¯å¢ƒè§„åˆ’

```yaml
deployment_environments:
  development:
    purpose: "å¼€å‘æµ‹è¯•ç¯å¢ƒ"
    infrastructure: "æœ¬åœ°Docker + Docker Compose"
    database: "PostgreSQL å•å®ä¾‹"
    cache: "Redis å•å®ä¾‹"
    monitoring: "åŸºç¡€ç›‘æ§"
    ci_cd: "GitHub Actions"

  staging:
    purpose: "é¢„ç”Ÿäº§ç¯å¢ƒ"
    infrastructure: "äº‘æœåŠ¡å•† (é˜¿é‡Œäº‘/AWS)"
    database: "PostgreSQL ä¸»ä»"
    cache: "Redis é›†ç¾¤"
    monitoring: "å®Œæ•´ç›‘æ§"
    ci_cd: "GitHub Actions"
    testing: "è‡ªåŠ¨åŒ–æµ‹è¯•"

  production:
    purpose: "ç”Ÿäº§ç¯å¢ƒ"
    infrastructure: "äº‘æœåŠ¡å•† (é˜¿é‡Œäº‘/AWS) + CDN"
    database: "PostgreSQL é«˜å¯ç”¨é›†ç¾¤"
    cache: "Redis é«˜å¯ç”¨é›†ç¾¤"
    monitoring: "å…¨é¢ç›‘æ§ + å‘Šè­¦"
    ci_cd: "GitHub Actions + è“ç»¿éƒ¨ç½²"
    backup: "å®šæœŸå¤‡ä»½ + ç¾å¤‡"
```

### 6.2 å®¹å™¨åŒ–æ¶æ„

#### 6.2.1 Dockerå®¹å™¨åŒ–è®¾è®¡

**å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–**ï¼š
```dockerfile
# Dockerfile - å‰ç«¯åº”ç”¨ (Flutter Web)
# é˜¶æ®µ1: æ„å»ºé˜¶æ®µ
FROM cirrusci/flutter:3.13.0 as builder

WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY pubspec.yaml pubspec.lock ./
COPY .packages .packages

# å®‰è£…ä¾èµ–
RUN flutter pub get

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºWebåº”ç”¨
RUN flutter config --enable-web
RUN flutter build web --release --web-renderer canvaskit --no-web-resources-cdn

# é˜¶æ®µ2: ç”Ÿäº§é˜¶æ®µ
FROM nginx:alpine as production

# å¤åˆ¶nginxé…ç½®
COPY nginx.conf /etc/nginx/nginx.conf

# å¤åˆ¶æ„å»ºäº§ç‰©
COPY --from=builder /app/build/web /usr/share/nginx/html

# æ·»åŠ å¥åº·æ£€æŸ¥
COPY healthcheck.sh /healthcheck.sh
RUN chmod +x /healthcheck.sh

HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD /healthcheck.sh

# æš´éœ²ç«¯å£
EXPOSE 80

# å¯åŠ¨nginx
CMD ["nginx", "-g", "daemon off;"]
```

**åç«¯APIå®¹å™¨åŒ–**ï¼š
```dockerfile
# Dockerfile - åç«¯API (FastAPI)
FROM python:3.11-slim as builder

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºérootç”¨æˆ·
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# å¯åŠ¨åº”ç”¨
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 6.2.2 Docker Composeç¼–æ’

**å¼€å‘ç¯å¢ƒç¼–æ’**ï¼š
```yaml
# docker-compose.dev.yml - å¼€å‘ç¯å¢ƒ
version: '3.8'

services:
  # å‰ç«¯åº”ç”¨
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    ports:
      - "3000:80"
    volumes:
      - ./frontend:/app
      - /app/build
    environment:
      - FLUTTER_WEB_CANVASKIT=enabled
    depends_on:
      - backend
    networks:
      - jisu-network

  # åç«¯API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - /app/__pycache__
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/jisu_dev
      - REDIS_URL=redis://redis:6379/0
      - DEBUG=true
    depends_on:
      - db
      - redis
    networks:
      - jisu-network

  # æ•°æ®åº“
  db:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=jisu_dev
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - jisu-network

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - jisu-network

  # æ•°æ®é‡‡é›†æœåŠ¡
  data_collector:
    build:
      context: ./data_collector
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/jisu_dev
      - REDIS_URL=redis://redis:6379/0
      - AKSHARE_API_KEY=${AKSHARE_API_KEY}
    depends_on:
      - db
      - redis
    networks:
      - jisu-network

volumes:
  postgres_data:
  redis_data:

networks:
  jisu-network:
    driver: bridge
```

**ç”Ÿäº§ç¯å¢ƒç¼–æ’**ï¼š
```yaml
# docker-compose.prod.yml - ç”Ÿäº§ç¯å¢ƒ
version: '3.8'

services:
  # è´Ÿè½½å‡è¡¡å™¨
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - ./nginx/logs:/var/log/nginx
    depends_on:
      - frontend-1
      - frontend-2
      - backend-1
      - backend-2
    networks:
      - jisu-network
    restart: unless-stopped

  # å‰ç«¯åº”ç”¨å®ä¾‹1
  frontend-1:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=production
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    networks:
      - jisu-network
    restart: unless-stopped

  # å‰ç«¯åº”ç”¨å®ä¾‹2
  frontend-2:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=production
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    networks:
      - jisu-network
    restart: unless-stopped

  # åç«¯APIå®ä¾‹1
  backend-1:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
      - DEBUG=false
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    depends_on:
      - db-master
      - redis-master
    networks:
      - jisu-network
    restart: unless-stopped

  # åç«¯APIå®ä¾‹2
  backend-2:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
      - DEBUG=false
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    depends_on:
      - db-master
      - redis-master
    networks:
      - jisu-network
    restart: unless-stopped

  # æ•°æ®åº“ä¸»èŠ‚ç‚¹
  db-master:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_REPLICATION_MODE=master
      - POSTGRES_REPLICATION_USER=replicator
      - POSTGRES_REPLICATION_PASSWORD=${REPLICATION_PASSWORD}
    volumes:
      - postgres_master_data:/var/lib/postgresql/data
      - ./database/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./database/pg_hba.conf:/etc/postgresql/pg_hba.conf
    networks:
      - jisu-network
    restart: unless-stopped

  # æ•°æ®åº“ä»èŠ‚ç‚¹1
  db-slave-1:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_MASTER_SERVICE=db-master
      - POSTGRES_REPLICATION_MODE=slave
      - POSTGRES_REPLICATION_USER=replicator
      - POSTGRES_REPLICATION_PASSWORD=${REPLICATION_PASSWORD}
      - PGUSER=${POSTGRES_USER}
    volumes:
      - postgres_slave1_data:/var/lib/postgresql/data
    depends_on:
      - db-master
    networks:
      - jisu-network
    restart: unless-stopped

  # Redisä¸»èŠ‚ç‚¹
  redis-master:
    image: redis:7-alpine
    command: redis-server --appendonly yes --replica-announce-ip redis-master
    volumes:
      - redis_master_data:/data
    networks:
      - jisu-network
    restart: unless-stopped

  # Redisä»èŠ‚ç‚¹1
  redis-slave-1:
    image: redis:7-alpine
    command: redis-server --slaveof redis-master 6379 --replica-announce-ip redis-slave-1
    depends_on:
      - redis-master
    networks:
      - jisu-network
    restart: unless-stopped

volumes:
  postgres_master_data:
  postgres_slave1_data:
  redis_master_data:

networks:
  jisu-network:
    external: true
```

### 6.3 Kubernetesé›†ç¾¤éƒ¨ç½²

#### 6.3.1 Kubernetesé…ç½®

**å‘½åç©ºé—´å’Œèµ„æºé…ç½®**ï¼š
```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: jisu-prod
  labels:
    name: jisu-prod

---
# k8s/resource-quota.yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: jisu-quota
  namespace: jisu-prod
spec:
  hard:
    requests.cpu: "10"
    requests.memory: 20Gi
    limits.cpu: "20"
    limits.memory: 40Gi
    persistentvolumeclaims: "10"
    services: "20"
    secrets: "20"
    configmaps: "20"

---
# k8s/limit-range.yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: jisu-limits
  namespace: jisu-prod
spec:
  limits:
  - default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "100m"
      memory: "128Mi"
    type: Container
```

**å‰ç«¯éƒ¨ç½²é…ç½®**ï¼š
```yaml
# k8s/frontend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  namespace: jisu-prod
  labels:
    app: frontend
    version: v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
        version: v1
    spec:
      containers:
      - name: frontend
        image: jisu/frontend:latest
        ports:
        - containerPort: 80
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
        env:
        - name: NODE_ENV
          value: "production"
        volumeMounts:
        - name: nginx-config
          mountPath: /etc/nginx/conf.d
      volumes:
      - name: nginx-config
        configMap:
          name: nginx-config

---
# k8s/frontend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: frontend-service
  namespace: jisu-prod
  labels:
    app: frontend
spec:
  selector:
    app: frontend
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP

---
# k8s/frontend-hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: frontend-hpa
  namespace: jisu-prod
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: frontend
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

**åç«¯APIéƒ¨ç½²é…ç½®**ï¼š
```yaml
# k8s/backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  namespace: jisu-prod
  labels:
    app: backend
    version: v1
spec:
  replicas: 5
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
        version: v1
    spec:
      containers:
      - name: backend
        image: jisu/backend:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: jisu-secrets
              key: DATABASE_URL
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: jisu-secrets
              key: REDIS_URL
        - name: SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: jisu-secrets
              key: SECRET_KEY
        volumeMounts:
        - name: app-logs
          mountPath: /app/logs
      volumes:
      - name: app-logs
        emptyDir: {}

---
# k8s/backend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: backend-service
  namespace: jisu-prod
  labels:
    app: backend
spec:
  selector:
    app: backend
  ports:
  - protocol: TCP
    port: 8000
    targetPort: 8000
  type: ClusterIP

---
# k8s/backend-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: backend-config
  namespace: jisu-prod
data:
  DATABASE_HOST: "postgres-service"
  DATABASE_PORT: "5432"
  REDIS_HOST: "redis-service"
  REDIS_PORT: "6379"
  LOG_LEVEL: "INFO"
  MAX_CONNECTIONS: "20"
  CACHE_TTL: "3600"

---
# k8s/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: jisu-secrets
  namespace: jisu-prod
type: Opaque
data:
  DATABASE_URL: <base64-encoded-database-url>
  REDIS_URL: <base64-encoded-redis-url>
  SECRET_KEY: <base64-encoded-secret-key>
  AKSHARE_API_KEY: <base64-encoded-api-key>
```

### 6.4 CI/CDæµæ°´çº¿

#### 6.4.1 GitHub Actionså·¥ä½œæµ

**ä¸»CI/CDæµæ°´çº¿**ï¼š
```yaml
# .github/workflows/main.yml
name: Build and Deploy

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt

    - name: Run linting
      run: |
        flake8 app/ tests/
        black --check app/ tests/
        isort --check-only app/ tests/

    - name: Run security checks
      run: |
        bandit -r app/
        safety check

    - name: Run tests
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379/0
      run: |
        pytest tests/ -v --cov=app --cov-report=xml --cov-report=html

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build-frontend:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Flutter
      uses: subosito/flutter-action@v2
      with:
        flutter-version: '3.13.x'
        channel: 'stable'
        cache: true

    - name: Install dependencies
      run: flutter pub get

    - name: Build Flutter Web
      run: flutter build web --release

    - name: Build Docker image
      run: |
        docker build -t $REGISTRY/$IMAGE_NAME:frontend-latest ./frontend

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Push Docker image
      run: |
        docker tag $REGISTRY/$IMAGE_NAME:frontend-latest $REGISTRY/$IMAGE_NAME:frontend-${{ github.sha }}
        docker push $REGISTRY/$IMAGE_NAME:frontend-latest
        docker push $REGISTRY/$IMAGE_NAME:frontend-${{ github.sha }}

  build-backend:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: ./backend
        push: true
        tags: |
          ${{ env.REGISTRY }}/$IMAGE_NAME:backend-latest
          ${{ env.REGISTRY }}/$IMAGE_NAME:backend-${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy-staging:
    runs-on: ubuntu-latest
    needs: [build-frontend, build-backend]
    if: github.ref == 'refs/heads/develop'
    environment: staging

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG }}

    - name: Deploy to staging
      run: |
        kubectl apply -f k8s/staging/
        kubectl rollout status deployment/frontend -n jisu-staging
        kubectl rollout status deployment/backend -n jisu-staging

    - name: Run integration tests
      run: |
        kubectl wait --for=condition=available deployment/frontend -n jisu-staging --timeout=300s
        kubectl wait --for=condition=available deployment/backend -n jisu-staging --timeout=300s

        # è¿è¡Œé›†æˆæµ‹è¯•
        pytest tests/integration/ --base-url=https://staging.jisu.com

  deploy-production:
    runs-on: ubuntu-latest
    needs: [build-frontend, build-backend]
    if: github.ref == 'refs/heads/main'
    environment: production

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG_PROD }}

    - name: Deploy to production (Blue-Green)
      run: |
        # éƒ¨ç½²åˆ°ç»¿è‰²ç¯å¢ƒ
        sed 's/jisu-blue/jisu-green/g' k8s/production/deployment.yaml | kubectl apply -f -

        # ç­‰å¾…ç»¿è‰²ç¯å¢ƒå°±ç»ª
        kubectl rollout status deployment/frontend-green -n jisu-prod
        kubectl rollout status deployment/backend-green -n jisu-prod

        # å¥åº·æ£€æŸ¥
        kubectl wait --for=condition=available deployment/frontend-green -n jisu-prod --timeout=600s
        kubectl wait --for=condition=available deployment/backend-green -n jisu-prod --timeout=600s

        # åˆ‡æ¢æµé‡
        kubectl patch service frontend-service -n jisu-prod -p '{"spec":{"selector":{"version":"green"}}}'
        kubectl patch service backend-service -n jisu-prod -p '{"spec":{"selector":{"version":"green"}}}'

        # éªŒè¯åˆ‡æ¢
        sleep 30
        curl -f https://api.jisu.com/health

    - name: Run smoke tests
      run: |
        pytest tests/smoke/ --base-url=https://api.jisu.com

    - name: Cleanup blue environment
      run: |
        # æ¸…ç†è“è‰²ç¯å¢ƒ
        kubectl delete deployment/frontend-blue -n jisu-prod --ignore-not-found=true
        kubectl delete deployment/backend-blue -n jisu-prod --ignore-not-found=true
```

### 6.5 ç›‘æ§ä¸æ—¥å¿—

#### 6.5.1 ç›‘æ§æ¶æ„

**Prometheus + Grafanaç›‘æ§**ï¼š
```yaml
# k8s/monitoring/prometheus-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus:latest
        ports:
        - containerPort: 9090
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus
        - name: prometheus-storage
          mountPath: /prometheus
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus'
          - '--web.console.libraries=/etc/prometheus/console_libraries'
          - '--web.console.templates=/etc/prometheus/consoles'
          - '--storage.tsdb.retention.time=30d'
          - '--web.enable-lifecycle'
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
      - name: prometheus-storage
        persistentVolumeClaim:
          claimName: prometheus-pvc

---
# k8s/monitoring/grafana-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:latest
        ports:
        - containerPort: 3000
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-secrets
              key: admin-password
        - name: GF_INSTALL_PLUGINS
          value: "grafana-piechart-panel,grafana-worldmap-panel"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
        - name: grafana-config
          mountPath: /etc/grafana
      volumes:
      - name: grafana-storage
        persistentVolumeClaim:
          claimName: grafana-pvc
      - name: grafana-config
        configMap:
          name: grafana-config
```

**ç›‘æ§é…ç½®**ï¼š
```yaml
# k8s/monitoring/prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    rule_files:
      - "/etc/prometheus/rules/*.yml"

    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093

    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)

      - job_name: 'frontend'
        static_configs:
          - targets: ['frontend-service.jisu-prod.svc.cluster.local:80']
        metrics_path: /metrics

      - job_name: 'backend'
        static_configs:
          - targets: ['backend-service.jisu-prod.svc.cluster.local:8000']
        metrics_path: /metrics

      - job_name: 'postgres'
        static_configs:
          - targets: ['postgres-exporter.jisu-prod.svc.cluster.local:9187']

      - job_name: 'redis'
        static_configs:
          - targets: ['redis-exporter.jisu-prod.svc.cluster.local:9121']

  alert_rules.yml: |
    groups:
    - name: jisu-alerts
      rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"

      - alert: HighMemoryUsage
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is above 80%"

      - alert: DatabaseConnectionsHigh
        expr: pg_stat_activity_count > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High database connections"
          description: "Database has {{ $value }} active connections"
```

#### 6.5.2 æ—¥å¿—ç®¡ç†

**ELK Stackæ—¥å¿—ç®¡ç†**ï¼š
```yaml
# k8s/logging/elasticsearch-deployment.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: logging
spec:
  serviceName: elasticsearch
  replicas: 3
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
        ports:
        - containerPort: 9200
        - containerPort: 9300
        env:
        - name: discovery.type
          value: single-node
        - name: ES_JAVA_OPTS
          value: "-Xms1g -Xmx1g"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        volumeMounts:
        - name: elasticsearch-data
          mountPath: /usr/share/elasticsearch/data
  volumeClaimTemplates:
  - metadata:
      name: elasticsearch-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi

---
# k8s/logging/logstash-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: logstash
  namespace: logging
spec:
  replicas: 2
  selector:
    matchLabels:
      app: logstash
  template:
    metadata:
      labels:
        app: logstash
    spec:
      containers:
      - name: logstash
        image: docker.elastic.co/logstash/logstash:8.8.0
        ports:
        - containerPort: 5044
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        volumeMounts:
        - name: logstash-config
          mountPath: /usr/share/logstash/pipeline
        - name: logstash-logs
          mountPath: /usr/share/logstash/logs
      volumes:
      - name: logstash-config
        configMap:
          name: logstash-config
      - name: logstash-logs
        emptyDir: {}

---
# k8s/logging/kibana-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: logging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana:8.8.0
        ports:
        - containerPort: 5601
        env:
        - name: ELASTICSEARCH_HOSTS
          value: "http://elasticsearch.logging.svc.cluster.local:9200"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
```

**Logstashé…ç½®**ï¼š
```ruby
# logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  # è§£æJSONæ—¥å¿—
  if [fields][logtype] == "application" {
    json {
      source => "message"
    }

    # è§£ææ—¶é—´æˆ³
    date {
      match => [ "timestamp", "ISO8601" ]
    }

    # æ·»åŠ ç¯å¢ƒæ ‡ç­¾
    mutate {
      add_field => { "environment" => "%{[fields][environment]}" }
    }
  }

  # è§£æNginxè®¿é—®æ—¥å¿—
  if [fields][logtype] == "nginx" {
    grok {
      match => {
        "message" => "%{COMBINEDAPACHELOG}"
      }
    }

    # è§£æIPåœ°å€åœ°ç†ä½ç½®
    if [clientip] {
      geoip {
        source => "clientip"
        target => "geoip"
      }
    }
  }

  # è§£æDockerå®¹å™¨æ—¥å¿—
  if [fields][logtype] == "docker" {
    json {
      source => "message"
    }

    # æå–å®¹å™¨ä¿¡æ¯
    if [container_name] {
      mutate {
        add_field => { "container_name" => "%{container_name}" }
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch.logging.svc.cluster.local:9200"]
    index => "jisu-logs-%{+YYYY.MM.dd}"
  }

  # å¼€å‘ç¯å¢ƒå¯ä»¥åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
  if [fields][environment] == "development" {
    stdout {
      codec => rubydebug
    }
  }
}
```

### 6.6 å¤‡ä»½ä¸ç¾éš¾æ¢å¤

#### 6.6.1 æ•°æ®å¤‡ä»½ç­–ç•¥

**è‡ªåŠ¨åŒ–å¤‡ä»½è„šæœ¬**ï¼š
```bash
#!/bin/bash
# backup.sh - è‡ªåŠ¨åŒ–å¤‡ä»½è„šæœ¬

set -e

# é…ç½®å˜é‡
BACKUP_DIR="/backup"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30
S3_BUCKET="jisu-backups"
SLACK_WEBHOOK="${SLACK_WEBHOOK_URL}"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR/$DATE

# å‡½æ•°ï¼šè®°å½•æ—¥å¿—
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
    # å‘é€åˆ°Slack
    if [ -n "$SLACK_WEBHOOK" ]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"Backup: $1\"}" \
            "$SLACK_WEBHOOK" > /dev/null 2>&1
    fi
}

# å‡½æ•°ï¼šå‘é€å‘Šè­¦
send_alert() {
    local message="$1"
    if [ -n "$SLACK_WEBHOOK" ]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"ğŸš¨ ALERT: $message\"}" \
            "$SLACK_WEBHOOK" > /dev/null 2>&1
    fi
}

# å‡½æ•°ï¼šå¤‡ä»½PostgreSQLæ•°æ®åº“
backup_postgresql() {
    log "å¼€å§‹å¤‡ä»½PostgreSQLæ•°æ®åº“"

    # è·å–æ•°æ®åº“è¿æ¥ä¿¡æ¯
    DB_HOST="${POSTGRES_HOST:-localhost}"
    DB_PORT="${POSTGRES_PORT:-5432}"
    DB_NAME="${POSTGRES_DB:-jisu_prod}"
    DB_USER="${POSTGRES_USER:-postgres}"

    # æ‰§è¡Œå¤‡ä»½
    PGPASSWORD="$POSTGRES_PASSWORD" pg_dump \
        -h $DB_HOST \
        -p $DB_PORT \
        -U $DB_USER \
        -d $DB_NAME \
        --no-password \
        --format=custom \
        --compress=9 \
        --file=$BACKUP_DIR/$DATE/postgres_backup.dump

    if [ $? -eq 0 ]; then
        log "PostgreSQLæ•°æ®åº“å¤‡ä»½å®Œæˆ"

        # éªŒè¯å¤‡ä»½æ–‡ä»¶
        if [ -f "$BACKUP_DIR/$DATE/postgres_backup.dump" ]; then
            log "å¤‡ä»½æ–‡ä»¶å¤§å°: $(du -h $BACKUP_DIR/$DATE/postgres_backup.dump | cut -f1)"
        else
            send_alert "PostgreSQLå¤‡ä»½æ–‡ä»¶åˆ›å»ºå¤±è´¥"
            return 1
        fi
    else
        send_alert "PostgreSQLæ•°æ®åº“å¤‡ä»½å¤±è´¥"
        return 1
    fi
}

# å‡½æ•°ï¼šå¤‡ä»½Redisæ•°æ®
backup_redis() {
    log "å¼€å§‹å¤‡ä»½Redisæ•°æ®"

    REDIS_HOST="${REDIS_HOST:-localhost}"
    REDIS_PORT="${REDIS_PORT:-6379}"
    REDIS_PASSWORD="${REDIS_PASSWORD}"

    # ä½¿ç”¨redis-cliåˆ›å»ºRDBå¿«ç…§
    if [ -n "$REDIS_PASSWORD" ]; then
        redis-cli -h $REDIS_HOST -p $REDIS_PORT -a $REDIS_PASSWORD BGSAVE
    else
        redis-cli -h $REDIS_HOST -p $REDIS_PORT BGSAVE
    fi

    # ç­‰å¾…å¤‡ä»½å®Œæˆ
    sleep 5

    # å¤åˆ¶RDBæ–‡ä»¶
    REDIS_DATA_DIR="/var/lib/redis"
    if [ -f "$REDIS_DATA_DIR/dump.rdb" ]; then
        cp "$REDIS_DATA_DIR/dump.rdb" "$BACKUP_DIR/$DATE/redis_backup.rdb"
        log "Redisæ•°æ®å¤‡ä»½å®Œæˆ"
        log "Rediså¤‡ä»½æ–‡ä»¶å¤§å°: $(du -h $BACKUP_DIR/$DATE/redis_backup.rdb | cut -f1)"
    else
        send_alert "Rediså¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨"
        return 1
    fi
}

# å‡½æ•°ï¼šå¤‡ä»½åº”ç”¨ç¨‹åºé…ç½®
backup_app_config() {
    log "å¼€å§‹å¤‡ä»½åº”ç”¨é…ç½®"

    # å¤‡ä»½Kubernetesé…ç½®
    kubectl get configmaps,secrets,deployments,services \
        -n jisu-prod \
        -o yaml > $BACKUP_DIR/$DATE/k8s-configs.yaml

    # å¤‡ä»½Docker Composeé…ç½®ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    if [ -f "docker-compose.prod.yml" ]; then
        cp docker-compose.prod.yml $BACKUP_DIR/$DATE/
    fi

    # å¤‡ä»½ç¯å¢ƒå˜é‡
    env | grep -E '^(JISU_|DATABASE_|REDIS_)' > $BACKUP_DIR/$DATE/environment.env

    log "åº”ç”¨é…ç½®å¤‡ä»½å®Œæˆ"
}

# å‡½æ•°ï¼šå¤‡ä»½ç”¨æˆ·æ•°æ®
backup_user_data() {
    log "å¼€å§‹å¤‡ä»½ç”¨æˆ·æ•°æ®"

    # å¤‡ä»½ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶
    if [ -d "/data/uploads" ]; then
        tar -czf $BACKUP_DIR/$DATE/user_uploads.tar.gz -C /data/uploads .
        log "ç”¨æˆ·æ–‡ä»¶å¤‡ä»½å®Œæˆ"
    fi

    # å¤‡ä»½æ—¥å¿—æ–‡ä»¶
    if [ -d "/var/log/jisu" ]; then
        find /var/log/jisu -name "*.log" -mtime -7 -exec cp {} $BACKUP_DIR/$DATE/ \;
        log "æ—¥å¿—æ–‡ä»¶å¤‡ä»½å®Œæˆ"
    fi
}

# å‡½æ•°ï¼šä¸Šä¼ åˆ°äº‘å­˜å‚¨
upload_to_cloud() {
    log "å¼€å§‹ä¸Šä¼ å¤‡ä»½åˆ°äº‘å­˜å‚¨"

    # ä½¿ç”¨AWS S3
    if command -v aws >/dev/null 2>&1; then
        aws s3 sync $BACKUP_DIR/$DATE s3://$S3_BUCKET/$DATE/ --delete
        log "å¤‡ä»½å·²ä¸Šä¼ åˆ°AWS S3: s3://$S3_BUCKET/$DATE/"
    else
        log "AWS CLIæœªå®‰è£…ï¼Œè·³è¿‡äº‘å­˜å‚¨ä¸Šä¼ "
    fi
}

# å‡½æ•°ï¼šæ¸…ç†æ—§å¤‡ä»½
cleanup_old_backups() {
    log "å¼€å§‹æ¸…ç†$RETENTION_DAYSå¤©å‰çš„æ—§å¤‡ä»½"

    # åˆ é™¤æœ¬åœ°æ—§å¤‡ä»½
    find $BACKUP_DIR -type d -mtime +$RETENTION_DAYS -exec rm -rf {} +

    # æ¸…ç†äº‘å­˜å‚¨æ—§å¤‡ä»½
    if command -v aws >/dev/null 2>&1; then
        aws s3 ls s3://$S3_BUCKET/ | while read -r line; do
            backup_date=$(echo $line | awk '{print $2}')
            if [ -n "$backup_date" ]; then
                backup_timestamp=$(date -d "$backup_date" +%s)
                cutoff_timestamp=$(date -d "$RETENTION_DAYS days ago" +%s)

                if [ "$backup_timestamp" -lt "$cutoff_timestamp" ]; then
                    aws s3 rm --recursive s3://$S3_BUCKET/$backup_date/
                    log "åˆ é™¤æ—§å¤‡ä»½: $backup_date"
                fi
            fi
        done
    fi

    log "æ—§å¤‡ä»½æ¸…ç†å®Œæˆ"
}

# å‡½æ•°ï¼šéªŒè¯å¤‡ä»½å®Œæ•´æ€§
verify_backup() {
    log "å¼€å§‹éªŒè¯å¤‡ä»½å®Œæ•´æ€§"

    local backup_path="$BACKUP_DIR/$DATE"
    local verification_failed=false

    # éªŒè¯PostgreSQLå¤‡ä»½
    if [ -f "$backup_path/postgres_backup.dump" ]; then
        pg_restore --list "$backup_path/postgres_backup.dump" > /dev/null 2>&1
        if [ $? -eq 0 ]; then
            log "PostgreSQLå¤‡ä»½éªŒè¯é€šè¿‡"
        else
            send_alert "PostgreSQLå¤‡ä»½éªŒè¯å¤±è´¥"
            verification_failed=true
        fi
    else
        send_alert "PostgreSQLå¤‡ä»½æ–‡ä»¶ç¼ºå¤±"
        verification_failed=true
    fi

    # éªŒè¯Rediså¤‡ä»½
    if [ -f "$backup_path/redis_backup.rdb" ]; then
        redis-cli --rdb "$backup_path/redis_backup.rdb" --test > /dev/null 2>&1
        if [ $? -eq 0 ]; then
            log "Rediså¤‡ä»½éªŒè¯é€šè¿‡"
        else
            send_alert "Rediså¤‡ä»½éªŒè¯å¤±è´¥"
            verification_failed=true
        fi
    else
        send_alert "Rediså¤‡ä»½æ–‡ä»¶ç¼ºå¤±"
        verification_failed=true
    fi

    if [ "$verification_failed" = true ]; then
        return 1
    fi

    log "æ‰€æœ‰å¤‡ä»½éªŒè¯é€šè¿‡"
    return 0
}

# ä¸»æ‰§è¡Œæµç¨‹
main() {
    log "å¼€å§‹æ‰§è¡Œå¤‡ä»½æµç¨‹ - æ—¥æœŸ: $DATE"

    # åˆ›å»ºå¤‡ä»½ç›®å½•
    mkdir -p $BACKUP_DIR/$DATE

    # æ‰§è¡Œå¤‡ä»½
    backup_postgresql || exit 1
    backup_redis || exit 1
    backup_app_config || exit 1
    backup_user_data || exit 1

    # éªŒè¯å¤‡ä»½
    verify_backup || exit 1

    # ä¸Šä¼ åˆ°äº‘å­˜å‚¨
    upload_to_cloud

    # æ¸…ç†æ—§å¤‡ä»½
    cleanup_old_backups

    # ç”Ÿæˆå¤‡ä»½æŠ¥å‘Š
    BACKUP_SIZE=$(du -sh $BACKUP_DIR/$DATE | cut -f1)
    BACKUP_FILES=$(find $BACKUP_DIR/$DATE -type f | wc -l)

    log "å¤‡ä»½æµç¨‹å®Œæˆ!"
    log "å¤‡ä»½ä½ç½®: $BACKUP_DIR/$DATE"
    log "å¤‡ä»½å¤§å°: $BACKUP_SIZE"
    log "å¤‡ä»½æ–‡ä»¶æ•°: $BACKUP_FILES"
    log "å¤‡ä»½å·²ä¸Šä¼ åˆ°äº‘å­˜å‚¨: s3://$S3_BUCKET/$DATE/"
}

# é”™è¯¯å¤„ç†
trap 'send_alert "å¤‡ä»½è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"; exit 1' ERR

# æ‰§è¡Œä¸»å‡½æ•°
main

exit 0
```

**Cronå®šæ—¶ä»»åŠ¡é…ç½®**ï¼š
```bash
# crontab -e
# æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œå®Œæ•´å¤‡ä»½
0 2 * * * /opt/jisu/scripts/backup.sh >> /var/log/backup.log 2>&1

# æ¯å‘¨æ—¥å‡Œæ™¨3ç‚¹æ‰§è¡Œå¢é‡å¤‡ä»½
0 3 * * 0 /opt/jisu/scripts/incremental_backup.sh >> /var/log/incremental_backup.log 2>&1

# æ¯æœˆ1å·æ‰§è¡Œæœˆåº¦å½’æ¡£
0 4 1 * * /opt/jisu/scripts/monthly_archive.sh >> /var/log/monthly_archive.log 2>&1

# æ¯å¤©æ£€æŸ¥å¤‡ä»½å®Œæ•´æ€§
0 6 * * * /opt/jisu/scripts/backup_verification.sh >> /var/log/backup_verification.log 2>&1
```

---

*æœ¬ç« èŠ‚è¯¦ç»†è¯´æ˜äº†åŸºé€Ÿå¹³å°çš„éƒ¨ç½²æ¶æ„è®¾è®¡ï¼ŒåŒ…æ‹¬å®¹å™¨åŒ–ã€Kubernetesé›†ç¾¤ã€CI/CDæµæ°´çº¿ã€ç›‘æ§æ—¥å¿—å’Œå¤‡ä»½æ¢å¤ç­‰å„ä¸ªæ–¹é¢çš„éƒ¨ç½²è¿ç»´ä½“ç³»*