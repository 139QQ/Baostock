# 6. 部署架构

## 🚀 部署架构概述

基速基金量化分析平台采用现代化的云原生部署架构，支持多环境部署、自动化CI/CD流水线、容器化管理和弹性扩展。本章节详细说明平台的部署架构设计、环境配置、监控运维等各个方面。

### 6.1 部署架构目标

#### 6.1.1 核心部署目标

**高可用性 (High Availability)**
- 系统可用性达到99.9%以上
- 支持故障自动切换和恢复
- 多区域部署避免单点故障
- 负载均衡确保服务连续性

**可扩展性 (Scalability)**
- 支持水平扩展应对用户增长
- 自动扩缩容机制优化资源使用
- 微服务架构支持独立扩展
- 无缝升级和版本管理

**安全性 (Security)**
- 生产环境全面的安全防护
- 网络隔离和访问控制
- 数据加密和安全传输
- 安全监控和威胁检测

**运维效率 (Operational Efficiency)**
- 自动化部署和运维流程
- 完善的监控告警体系
- 快速的问题定位和恢复
- 标准化的运维操作

#### 6.1.2 部署环境规划

```yaml
deployment_environments:
  development:
    purpose: "开发测试环境"
    infrastructure: "本地Docker + Docker Compose"
    database: "PostgreSQL 单实例"
    cache: "Redis 单实例"
    monitoring: "基础监控"
    ci_cd: "GitHub Actions"

  staging:
    purpose: "预生产环境"
    infrastructure: "云服务商 (阿里云/AWS)"
    database: "PostgreSQL 主从"
    cache: "Redis 集群"
    monitoring: "完整监控"
    ci_cd: "GitHub Actions"
    testing: "自动化测试"

  production:
    purpose: "生产环境"
    infrastructure: "云服务商 (阿里云/AWS) + CDN"
    database: "PostgreSQL 高可用集群"
    cache: "Redis 高可用集群"
    monitoring: "全面监控 + 告警"
    ci_cd: "GitHub Actions + 蓝绿部署"
    backup: "定期备份 + 灾备"
```

### 6.2 容器化架构

#### 6.2.1 Docker容器化设计

**多阶段构建优化**：
```dockerfile
# Dockerfile - 前端应用 (Flutter Web)
# 阶段1: 构建阶段
FROM cirrusci/flutter:3.13.0 as builder

WORKDIR /app

# 复制依赖文件
COPY pubspec.yaml pubspec.lock ./
COPY .packages .packages

# 安装依赖
RUN flutter pub get

# 复制源代码
COPY . .

# 构建Web应用
RUN flutter config --enable-web
RUN flutter build web --release --web-renderer canvaskit --no-web-resources-cdn

# 阶段2: 生产阶段
FROM nginx:alpine as production

# 复制nginx配置
COPY nginx.conf /etc/nginx/nginx.conf

# 复制构建产物
COPY --from=builder /app/build/web /usr/share/nginx/html

# 添加健康检查
COPY healthcheck.sh /healthcheck.sh
RUN chmod +x /healthcheck.sh

HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD /healthcheck.sh

# 暴露端口
EXPOSE 80

# 启动nginx
CMD ["nginx", "-g", "daemon off;"]
```

**后端API容器化**：
```dockerfile
# Dockerfile - 后端API (FastAPI)
FROM python:3.11-slim as builder

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY requirements.txt .

# 安装Python依赖
RUN pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY . .

# 创建非root用户
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# 暴露端口
EXPOSE 8000

# 健康检查
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# 启动应用
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 6.2.2 Docker Compose编排

**开发环境编排**：
```yaml
# docker-compose.dev.yml - 开发环境
version: '3.8'

services:
  # 前端应用
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    ports:
      - "3000:80"
    volumes:
      - ./frontend:/app
      - /app/build
    environment:
      - FLUTTER_WEB_CANVASKIT=enabled
    depends_on:
      - backend
    networks:
      - jisu-network

  # 后端API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - /app/__pycache__
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/jisu_dev
      - REDIS_URL=redis://redis:6379/0
      - DEBUG=true
    depends_on:
      - db
      - redis
    networks:
      - jisu-network

  # 数据库
  db:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=jisu_dev
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - jisu-network

  # Redis缓存
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - jisu-network

  # 数据采集服务
  data_collector:
    build:
      context: ./data_collector
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/jisu_dev
      - REDIS_URL=redis://redis:6379/0
      - AKSHARE_API_KEY=${AKSHARE_API_KEY}
    depends_on:
      - db
      - redis
    networks:
      - jisu-network

volumes:
  postgres_data:
  redis_data:

networks:
  jisu-network:
    driver: bridge
```

**生产环境编排**：
```yaml
# docker-compose.prod.yml - 生产环境
version: '3.8'

services:
  # 负载均衡器
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - ./nginx/logs:/var/log/nginx
    depends_on:
      - frontend-1
      - frontend-2
      - backend-1
      - backend-2
    networks:
      - jisu-network
    restart: unless-stopped

  # 前端应用实例1
  frontend-1:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=production
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    networks:
      - jisu-network
    restart: unless-stopped

  # 前端应用实例2
  frontend-2:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=production
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    networks:
      - jisu-network
    restart: unless-stopped

  # 后端API实例1
  backend-1:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
      - DEBUG=false
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    depends_on:
      - db-master
      - redis-master
    networks:
      - jisu-network
    restart: unless-stopped

  # 后端API实例2
  backend-2:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
      - DEBUG=false
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    depends_on:
      - db-master
      - redis-master
    networks:
      - jisu-network
    restart: unless-stopped

  # 数据库主节点
  db-master:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_REPLICATION_MODE=master
      - POSTGRES_REPLICATION_USER=replicator
      - POSTGRES_REPLICATION_PASSWORD=${REPLICATION_PASSWORD}
    volumes:
      - postgres_master_data:/var/lib/postgresql/data
      - ./database/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./database/pg_hba.conf:/etc/postgresql/pg_hba.conf
    networks:
      - jisu-network
    restart: unless-stopped

  # 数据库从节点1
  db-slave-1:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_MASTER_SERVICE=db-master
      - POSTGRES_REPLICATION_MODE=slave
      - POSTGRES_REPLICATION_USER=replicator
      - POSTGRES_REPLICATION_PASSWORD=${REPLICATION_PASSWORD}
      - PGUSER=${POSTGRES_USER}
    volumes:
      - postgres_slave1_data:/var/lib/postgresql/data
    depends_on:
      - db-master
    networks:
      - jisu-network
    restart: unless-stopped

  # Redis主节点
  redis-master:
    image: redis:7-alpine
    command: redis-server --appendonly yes --replica-announce-ip redis-master
    volumes:
      - redis_master_data:/data
    networks:
      - jisu-network
    restart: unless-stopped

  # Redis从节点1
  redis-slave-1:
    image: redis:7-alpine
    command: redis-server --slaveof redis-master 6379 --replica-announce-ip redis-slave-1
    depends_on:
      - redis-master
    networks:
      - jisu-network
    restart: unless-stopped

volumes:
  postgres_master_data:
  postgres_slave1_data:
  redis_master_data:

networks:
  jisu-network:
    external: true
```

### 6.3 Kubernetes集群部署

#### 6.3.1 Kubernetes配置

**命名空间和资源配置**：
```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: jisu-prod
  labels:
    name: jisu-prod

---
# k8s/resource-quota.yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: jisu-quota
  namespace: jisu-prod
spec:
  hard:
    requests.cpu: "10"
    requests.memory: 20Gi
    limits.cpu: "20"
    limits.memory: 40Gi
    persistentvolumeclaims: "10"
    services: "20"
    secrets: "20"
    configmaps: "20"

---
# k8s/limit-range.yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: jisu-limits
  namespace: jisu-prod
spec:
  limits:
  - default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "100m"
      memory: "128Mi"
    type: Container
```

**前端部署配置**：
```yaml
# k8s/frontend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  namespace: jisu-prod
  labels:
    app: frontend
    version: v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
        version: v1
    spec:
      containers:
      - name: frontend
        image: jisu/frontend:latest
        ports:
        - containerPort: 80
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
        env:
        - name: NODE_ENV
          value: "production"
        volumeMounts:
        - name: nginx-config
          mountPath: /etc/nginx/conf.d
      volumes:
      - name: nginx-config
        configMap:
          name: nginx-config

---
# k8s/frontend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: frontend-service
  namespace: jisu-prod
  labels:
    app: frontend
spec:
  selector:
    app: frontend
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP

---
# k8s/frontend-hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: frontend-hpa
  namespace: jisu-prod
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: frontend
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

**后端API部署配置**：
```yaml
# k8s/backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  namespace: jisu-prod
  labels:
    app: backend
    version: v1
spec:
  replicas: 5
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
        version: v1
    spec:
      containers:
      - name: backend
        image: jisu/backend:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: jisu-secrets
              key: DATABASE_URL
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: jisu-secrets
              key: REDIS_URL
        - name: SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: jisu-secrets
              key: SECRET_KEY
        volumeMounts:
        - name: app-logs
          mountPath: /app/logs
      volumes:
      - name: app-logs
        emptyDir: {}

---
# k8s/backend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: backend-service
  namespace: jisu-prod
  labels:
    app: backend
spec:
  selector:
    app: backend
  ports:
  - protocol: TCP
    port: 8000
    targetPort: 8000
  type: ClusterIP

---
# k8s/backend-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: backend-config
  namespace: jisu-prod
data:
  DATABASE_HOST: "postgres-service"
  DATABASE_PORT: "5432"
  REDIS_HOST: "redis-service"
  REDIS_PORT: "6379"
  LOG_LEVEL: "INFO"
  MAX_CONNECTIONS: "20"
  CACHE_TTL: "3600"

---
# k8s/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: jisu-secrets
  namespace: jisu-prod
type: Opaque
data:
  DATABASE_URL: <base64-encoded-database-url>
  REDIS_URL: <base64-encoded-redis-url>
  SECRET_KEY: <base64-encoded-secret-key>
  AKSHARE_API_KEY: <base64-encoded-api-key>
```

### 6.4 CI/CD流水线

#### 6.4.1 GitHub Actions工作流

**主CI/CD流水线**：
```yaml
# .github/workflows/main.yml
name: Build and Deploy

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt

    - name: Run linting
      run: |
        flake8 app/ tests/
        black --check app/ tests/
        isort --check-only app/ tests/

    - name: Run security checks
      run: |
        bandit -r app/
        safety check

    - name: Run tests
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379/0
      run: |
        pytest tests/ -v --cov=app --cov-report=xml --cov-report=html

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build-frontend:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Flutter
      uses: subosito/flutter-action@v2
      with:
        flutter-version: '3.13.x'
        channel: 'stable'
        cache: true

    - name: Install dependencies
      run: flutter pub get

    - name: Build Flutter Web
      run: flutter build web --release

    - name: Build Docker image
      run: |
        docker build -t $REGISTRY/$IMAGE_NAME:frontend-latest ./frontend

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Push Docker image
      run: |
        docker tag $REGISTRY/$IMAGE_NAME:frontend-latest $REGISTRY/$IMAGE_NAME:frontend-${{ github.sha }}
        docker push $REGISTRY/$IMAGE_NAME:frontend-latest
        docker push $REGISTRY/$IMAGE_NAME:frontend-${{ github.sha }}

  build-backend:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: ./backend
        push: true
        tags: |
          ${{ env.REGISTRY }}/$IMAGE_NAME:backend-latest
          ${{ env.REGISTRY }}/$IMAGE_NAME:backend-${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy-staging:
    runs-on: ubuntu-latest
    needs: [build-frontend, build-backend]
    if: github.ref == 'refs/heads/develop'
    environment: staging

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG }}

    - name: Deploy to staging
      run: |
        kubectl apply -f k8s/staging/
        kubectl rollout status deployment/frontend -n jisu-staging
        kubectl rollout status deployment/backend -n jisu-staging

    - name: Run integration tests
      run: |
        kubectl wait --for=condition=available deployment/frontend -n jisu-staging --timeout=300s
        kubectl wait --for=condition=available deployment/backend -n jisu-staging --timeout=300s

        # 运行集成测试
        pytest tests/integration/ --base-url=https://staging.jisu.com

  deploy-production:
    runs-on: ubuntu-latest
    needs: [build-frontend, build-backend]
    if: github.ref == 'refs/heads/main'
    environment: production

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG_PROD }}

    - name: Deploy to production (Blue-Green)
      run: |
        # 部署到绿色环境
        sed 's/jisu-blue/jisu-green/g' k8s/production/deployment.yaml | kubectl apply -f -

        # 等待绿色环境就绪
        kubectl rollout status deployment/frontend-green -n jisu-prod
        kubectl rollout status deployment/backend-green -n jisu-prod

        # 健康检查
        kubectl wait --for=condition=available deployment/frontend-green -n jisu-prod --timeout=600s
        kubectl wait --for=condition=available deployment/backend-green -n jisu-prod --timeout=600s

        # 切换流量
        kubectl patch service frontend-service -n jisu-prod -p '{"spec":{"selector":{"version":"green"}}}'
        kubectl patch service backend-service -n jisu-prod -p '{"spec":{"selector":{"version":"green"}}}'

        # 验证切换
        sleep 30
        curl -f https://api.jisu.com/health

    - name: Run smoke tests
      run: |
        pytest tests/smoke/ --base-url=https://api.jisu.com

    - name: Cleanup blue environment
      run: |
        # 清理蓝色环境
        kubectl delete deployment/frontend-blue -n jisu-prod --ignore-not-found=true
        kubectl delete deployment/backend-blue -n jisu-prod --ignore-not-found=true
```

### 6.5 监控与日志

#### 6.5.1 监控架构

**Prometheus + Grafana监控**：
```yaml
# k8s/monitoring/prometheus-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus:latest
        ports:
        - containerPort: 9090
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus
        - name: prometheus-storage
          mountPath: /prometheus
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus'
          - '--web.console.libraries=/etc/prometheus/console_libraries'
          - '--web.console.templates=/etc/prometheus/consoles'
          - '--storage.tsdb.retention.time=30d'
          - '--web.enable-lifecycle'
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
      - name: prometheus-storage
        persistentVolumeClaim:
          claimName: prometheus-pvc

---
# k8s/monitoring/grafana-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:latest
        ports:
        - containerPort: 3000
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-secrets
              key: admin-password
        - name: GF_INSTALL_PLUGINS
          value: "grafana-piechart-panel,grafana-worldmap-panel"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
        - name: grafana-config
          mountPath: /etc/grafana
      volumes:
      - name: grafana-storage
        persistentVolumeClaim:
          claimName: grafana-pvc
      - name: grafana-config
        configMap:
          name: grafana-config
```

**监控配置**：
```yaml
# k8s/monitoring/prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    rule_files:
      - "/etc/prometheus/rules/*.yml"

    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093

    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)

      - job_name: 'frontend'
        static_configs:
          - targets: ['frontend-service.jisu-prod.svc.cluster.local:80']
        metrics_path: /metrics

      - job_name: 'backend'
        static_configs:
          - targets: ['backend-service.jisu-prod.svc.cluster.local:8000']
        metrics_path: /metrics

      - job_name: 'postgres'
        static_configs:
          - targets: ['postgres-exporter.jisu-prod.svc.cluster.local:9187']

      - job_name: 'redis'
        static_configs:
          - targets: ['redis-exporter.jisu-prod.svc.cluster.local:9121']

  alert_rules.yml: |
    groups:
    - name: jisu-alerts
      rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"

      - alert: HighMemoryUsage
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is above 80%"

      - alert: DatabaseConnectionsHigh
        expr: pg_stat_activity_count > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High database connections"
          description: "Database has {{ $value }} active connections"
```

#### 6.5.2 日志管理

**ELK Stack日志管理**：
```yaml
# k8s/logging/elasticsearch-deployment.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: logging
spec:
  serviceName: elasticsearch
  replicas: 3
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
        ports:
        - containerPort: 9200
        - containerPort: 9300
        env:
        - name: discovery.type
          value: single-node
        - name: ES_JAVA_OPTS
          value: "-Xms1g -Xmx1g"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        volumeMounts:
        - name: elasticsearch-data
          mountPath: /usr/share/elasticsearch/data
  volumeClaimTemplates:
  - metadata:
      name: elasticsearch-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi

---
# k8s/logging/logstash-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: logstash
  namespace: logging
spec:
  replicas: 2
  selector:
    matchLabels:
      app: logstash
  template:
    metadata:
      labels:
        app: logstash
    spec:
      containers:
      - name: logstash
        image: docker.elastic.co/logstash/logstash:8.8.0
        ports:
        - containerPort: 5044
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        volumeMounts:
        - name: logstash-config
          mountPath: /usr/share/logstash/pipeline
        - name: logstash-logs
          mountPath: /usr/share/logstash/logs
      volumes:
      - name: logstash-config
        configMap:
          name: logstash-config
      - name: logstash-logs
        emptyDir: {}

---
# k8s/logging/kibana-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: logging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana:8.8.0
        ports:
        - containerPort: 5601
        env:
        - name: ELASTICSEARCH_HOSTS
          value: "http://elasticsearch.logging.svc.cluster.local:9200"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
```

**Logstash配置**：
```ruby
# logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  # 解析JSON日志
  if [fields][logtype] == "application" {
    json {
      source => "message"
    }

    # 解析时间戳
    date {
      match => [ "timestamp", "ISO8601" ]
    }

    # 添加环境标签
    mutate {
      add_field => { "environment" => "%{[fields][environment]}" }
    }
  }

  # 解析Nginx访问日志
  if [fields][logtype] == "nginx" {
    grok {
      match => {
        "message" => "%{COMBINEDAPACHELOG}"
      }
    }

    # 解析IP地址地理位置
    if [clientip] {
      geoip {
        source => "clientip"
        target => "geoip"
      }
    }
  }

  # 解析Docker容器日志
  if [fields][logtype] == "docker" {
    json {
      source => "message"
    }

    # 提取容器信息
    if [container_name] {
      mutate {
        add_field => { "container_name" => "%{container_name}" }
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch.logging.svc.cluster.local:9200"]
    index => "jisu-logs-%{+YYYY.MM.dd}"
  }

  # 开发环境可以同时输出到控制台
  if [fields][environment] == "development" {
    stdout {
      codec => rubydebug
    }
  }
}
```

### 6.6 备份与灾难恢复

#### 6.6.1 数据备份策略

**自动化备份脚本**：
```bash
#!/bin/bash
# backup.sh - 自动化备份脚本

set -e

# 配置变量
BACKUP_DIR="/backup"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30
S3_BUCKET="jisu-backups"
SLACK_WEBHOOK="${SLACK_WEBHOOK_URL}"

# 创建备份目录
mkdir -p $BACKUP_DIR/$DATE

# 函数：记录日志
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
    # 发送到Slack
    if [ -n "$SLACK_WEBHOOK" ]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"Backup: $1\"}" \
            "$SLACK_WEBHOOK" > /dev/null 2>&1
    fi
}

# 函数：发送告警
send_alert() {
    local message="$1"
    if [ -n "$SLACK_WEBHOOK" ]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"🚨 ALERT: $message\"}" \
            "$SLACK_WEBHOOK" > /dev/null 2>&1
    fi
}

# 函数：备份PostgreSQL数据库
backup_postgresql() {
    log "开始备份PostgreSQL数据库"

    # 获取数据库连接信息
    DB_HOST="${POSTGRES_HOST:-localhost}"
    DB_PORT="${POSTGRES_PORT:-5432}"
    DB_NAME="${POSTGRES_DB:-jisu_prod}"
    DB_USER="${POSTGRES_USER:-postgres}"

    # 执行备份
    PGPASSWORD="$POSTGRES_PASSWORD" pg_dump \
        -h $DB_HOST \
        -p $DB_PORT \
        -U $DB_USER \
        -d $DB_NAME \
        --no-password \
        --format=custom \
        --compress=9 \
        --file=$BACKUP_DIR/$DATE/postgres_backup.dump

    if [ $? -eq 0 ]; then
        log "PostgreSQL数据库备份完成"

        # 验证备份文件
        if [ -f "$BACKUP_DIR/$DATE/postgres_backup.dump" ]; then
            log "备份文件大小: $(du -h $BACKUP_DIR/$DATE/postgres_backup.dump | cut -f1)"
        else
            send_alert "PostgreSQL备份文件创建失败"
            return 1
        fi
    else
        send_alert "PostgreSQL数据库备份失败"
        return 1
    fi
}

# 函数：备份Redis数据
backup_redis() {
    log "开始备份Redis数据"

    REDIS_HOST="${REDIS_HOST:-localhost}"
    REDIS_PORT="${REDIS_PORT:-6379}"
    REDIS_PASSWORD="${REDIS_PASSWORD}"

    # 使用redis-cli创建RDB快照
    if [ -n "$REDIS_PASSWORD" ]; then
        redis-cli -h $REDIS_HOST -p $REDIS_PORT -a $REDIS_PASSWORD BGSAVE
    else
        redis-cli -h $REDIS_HOST -p $REDIS_PORT BGSAVE
    fi

    # 等待备份完成
    sleep 5

    # 复制RDB文件
    REDIS_DATA_DIR="/var/lib/redis"
    if [ -f "$REDIS_DATA_DIR/dump.rdb" ]; then
        cp "$REDIS_DATA_DIR/dump.rdb" "$BACKUP_DIR/$DATE/redis_backup.rdb"
        log "Redis数据备份完成"
        log "Redis备份文件大小: $(du -h $BACKUP_DIR/$DATE/redis_backup.rdb | cut -f1)"
    else
        send_alert "Redis备份文件不存在"
        return 1
    fi
}

# 函数：备份应用程序配置
backup_app_config() {
    log "开始备份应用配置"

    # 备份Kubernetes配置
    kubectl get configmaps,secrets,deployments,services \
        -n jisu-prod \
        -o yaml > $BACKUP_DIR/$DATE/k8s-configs.yaml

    # 备份Docker Compose配置（开发环境）
    if [ -f "docker-compose.prod.yml" ]; then
        cp docker-compose.prod.yml $BACKUP_DIR/$DATE/
    fi

    # 备份环境变量
    env | grep -E '^(JISU_|DATABASE_|REDIS_)' > $BACKUP_DIR/$DATE/environment.env

    log "应用配置备份完成"
}

# 函数：备份用户数据
backup_user_data() {
    log "开始备份用户数据"

    # 备份用户上传的文件
    if [ -d "/data/uploads" ]; then
        tar -czf $BACKUP_DIR/$DATE/user_uploads.tar.gz -C /data/uploads .
        log "用户文件备份完成"
    fi

    # 备份日志文件
    if [ -d "/var/log/jisu" ]; then
        find /var/log/jisu -name "*.log" -mtime -7 -exec cp {} $BACKUP_DIR/$DATE/ \;
        log "日志文件备份完成"
    fi
}

# 函数：上传到云存储
upload_to_cloud() {
    log "开始上传备份到云存储"

    # 使用AWS S3
    if command -v aws >/dev/null 2>&1; then
        aws s3 sync $BACKUP_DIR/$DATE s3://$S3_BUCKET/$DATE/ --delete
        log "备份已上传到AWS S3: s3://$S3_BUCKET/$DATE/"
    else
        log "AWS CLI未安装，跳过云存储上传"
    fi
}

# 函数：清理旧备份
cleanup_old_backups() {
    log "开始清理$RETENTION_DAYS天前的旧备份"

    # 删除本地旧备份
    find $BACKUP_DIR -type d -mtime +$RETENTION_DAYS -exec rm -rf {} +

    # 清理云存储旧备份
    if command -v aws >/dev/null 2>&1; then
        aws s3 ls s3://$S3_BUCKET/ | while read -r line; do
            backup_date=$(echo $line | awk '{print $2}')
            if [ -n "$backup_date" ]; then
                backup_timestamp=$(date -d "$backup_date" +%s)
                cutoff_timestamp=$(date -d "$RETENTION_DAYS days ago" +%s)

                if [ "$backup_timestamp" -lt "$cutoff_timestamp" ]; then
                    aws s3 rm --recursive s3://$S3_BUCKET/$backup_date/
                    log "删除旧备份: $backup_date"
                fi
            fi
        done
    fi

    log "旧备份清理完成"
}

# 函数：验证备份完整性
verify_backup() {
    log "开始验证备份完整性"

    local backup_path="$BACKUP_DIR/$DATE"
    local verification_failed=false

    # 验证PostgreSQL备份
    if [ -f "$backup_path/postgres_backup.dump" ]; then
        pg_restore --list "$backup_path/postgres_backup.dump" > /dev/null 2>&1
        if [ $? -eq 0 ]; then
            log "PostgreSQL备份验证通过"
        else
            send_alert "PostgreSQL备份验证失败"
            verification_failed=true
        fi
    else
        send_alert "PostgreSQL备份文件缺失"
        verification_failed=true
    fi

    # 验证Redis备份
    if [ -f "$backup_path/redis_backup.rdb" ]; then
        redis-cli --rdb "$backup_path/redis_backup.rdb" --test > /dev/null 2>&1
        if [ $? -eq 0 ]; then
            log "Redis备份验证通过"
        else
            send_alert "Redis备份验证失败"
            verification_failed=true
        fi
    else
        send_alert "Redis备份文件缺失"
        verification_failed=true
    fi

    if [ "$verification_failed" = true ]; then
        return 1
    fi

    log "所有备份验证通过"
    return 0
}

# 主执行流程
main() {
    log "开始执行备份流程 - 日期: $DATE"

    # 创建备份目录
    mkdir -p $BACKUP_DIR/$DATE

    # 执行备份
    backup_postgresql || exit 1
    backup_redis || exit 1
    backup_app_config || exit 1
    backup_user_data || exit 1

    # 验证备份
    verify_backup || exit 1

    # 上传到云存储
    upload_to_cloud

    # 清理旧备份
    cleanup_old_backups

    # 生成备份报告
    BACKUP_SIZE=$(du -sh $BACKUP_DIR/$DATE | cut -f1)
    BACKUP_FILES=$(find $BACKUP_DIR/$DATE -type f | wc -l)

    log "备份流程完成!"
    log "备份位置: $BACKUP_DIR/$DATE"
    log "备份大小: $BACKUP_SIZE"
    log "备份文件数: $BACKUP_FILES"
    log "备份已上传到云存储: s3://$S3_BUCKET/$DATE/"
}

# 错误处理
trap 'send_alert "备份脚本执行失败，请检查日志"; exit 1' ERR

# 执行主函数
main

exit 0
```

**Cron定时任务配置**：
```bash
# crontab -e
# 每天凌晨2点执行完整备份
0 2 * * * /opt/jisu/scripts/backup.sh >> /var/log/backup.log 2>&1

# 每周日凌晨3点执行增量备份
0 3 * * 0 /opt/jisu/scripts/incremental_backup.sh >> /var/log/incremental_backup.log 2>&1

# 每月1号执行月度归档
0 4 1 * * /opt/jisu/scripts/monthly_archive.sh >> /var/log/monthly_archive.log 2>&1

# 每天检查备份完整性
0 6 * * * /opt/jisu/scripts/backup_verification.sh >> /var/log/backup_verification.log 2>&1
```

---

*本章节详细说明了基速平台的部署架构设计，包括容器化、Kubernetes集群、CI/CD流水线、监控日志和备份恢复等各个方面的部署运维体系*