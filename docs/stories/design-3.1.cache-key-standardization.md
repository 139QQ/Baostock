# Story 3.1 ç¼“å­˜é”®æ ‡å‡†åŒ– - æŠ€æœ¯è®¾è®¡æ–‡æ¡£

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**åˆ›å»ºæ—¥æœŸ**: 2025-10-29
**ä½œè€…**: ç³»ç»Ÿæ¶æ„å¸ˆ
**é¡¹ç›®**: Baostock åŸºé‡‘ç®¡ç†ç³»ç»Ÿ
**å…³è”æ•…äº‹**: docs/stories/3.1.cache-key-standardization.md

## ğŸ¯ è®¾è®¡ç›®æ ‡

### ä¸»è¦ç›®æ ‡
1. **ç»Ÿä¸€å‘½åè§„èŒƒ**: å®ç°å…¨é¡¹ç›®ç»Ÿä¸€çš„ `module:type:identifier` ç¼“å­˜é”®å‘½åè§„èŒƒ
2. **è‡ªåŠ¨è¿ç§»**: å¼€å‘è‡ªåŠ¨åŒ–è¿ç§»å·¥å…·ï¼Œæ— ç¼è½¬æ¢ç°æœ‰ç¼“å­˜æ•°æ®
3. **å†²çªç®¡ç†**: å»ºç«‹å®Œå–„çš„å†²çªæ£€æµ‹å’Œè§£å†³æœºåˆ¶
4. **å‘åå…¼å®¹**: ç¡®ä¿è¿ç§»è¿‡ç¨‹ä¸­ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯ç”¨æ€§

### æ€§èƒ½ç›®æ ‡
- ç¼“å­˜é”®æŸ¥æ‰¾æ•ˆç‡æå‡ â‰¥ 20%
- è¿ç§»è¿‡ç¨‹é›¶æ•°æ®ä¸¢å¤±
- è¿ç§»åæ€§èƒ½ä¸ä½äºåŸæœ‰æ°´å¹³
- å†…å­˜ä½¿ç”¨ä¼˜åŒ– â‰¥ 15%

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„è®¾è®¡

### 1. æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç¼“å­˜é”®ç®¡ç†ç³»ç»Ÿ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   ç¼“å­˜é”®ç®¡ç†å™¨    â”‚  â”‚   è¿ç§»å¼•æ“       â”‚  â”‚   å†²çªæ£€æµ‹å™¨     â”‚  â”‚
â”‚  â”‚ CacheKeyManager â”‚  â”‚ MigrationEngine â”‚  â”‚ConflictDetector â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   é”®éªŒè¯å™¨       â”‚  â”‚   è¿›åº¦è·Ÿè¸ªå™¨     â”‚  â”‚   å›æ»šç®¡ç†å™¨     â”‚  â”‚
â”‚  â”‚  KeyValidator   â”‚  â”‚ ProgressTracker â”‚  â”‚RollbackManager  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      ç°æœ‰ç¼“å­˜ç³»ç»Ÿ                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ UnifiedHiveCacheâ”‚  â”‚ HiveCacheManagerâ”‚  â”‚ SharedPreferencesâ”‚  â”‚
â”‚  â”‚     Manager     â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. åˆ†å±‚æ¶æ„è®¾è®¡

#### 2.1 è¡¨ç°å±‚ (Presentation Layer)
```dart
abstract class CacheKeyManager {
  // ç”Ÿæˆæ ‡å‡†æ ¼å¼ç¼“å­˜é”®
  String generateKey(String module, String type, String identifier, {String version = 'v1'});

  // éªŒè¯ç¼“å­˜é”®æ ¼å¼
  bool validateKey(String key);

  // è§£æç¼“å­˜é”®ç»„ä»¶
  KeyComponents parseKey(String key);

  // æ£€æµ‹é”®å†²çª
  Future<List<KeyConflict>> detectConflicts(List<String> keys);

  // æ‰¹é‡ç”Ÿæˆé”®
  List<String> generateBatchKeys(String module, String type, List<String> identifiers);
}
```

#### 2.2 ä¸šåŠ¡é€»è¾‘å±‚ (Business Logic Layer)
```dart
class CacheKeyManagerImpl implements CacheKeyManager {
  final KeyValidator _validator;
  final ConflictDetector _conflictDetector;
  final KeyParser _parser;

  @override
  String generateKey(String module, String type, String identifier, {String version = 'v1'}) {
    // éªŒè¯è¾“å…¥å‚æ•°
    _validateInputs(module, type, identifier);

    // ç”Ÿæˆæ ‡å‡†é”®
    final key = '$module:$type:$identifier:$version';

    // éªŒè¯ç”Ÿæˆçš„é”®
    if (!_validator.validate(key)) {
      throw CacheKeyException('Invalid cache key generated: $key');
    }

    return key;
  }

  @override
  KeyComponents parseKey(String key) {
    if (!_validator.validate(key)) {
      throw CacheKeyException('Invalid cache key format: $key');
    }

    return _parser.parse(key);
  }
}
```

#### 2.3 æ•°æ®è®¿é—®å±‚ (Data Access Layer)
```dart
abstract class CacheKeyRepository {
  // ä¿å­˜é”®æ˜ å°„å…³ç³»
  Future<void> saveKeyMapping(Map<String, String> mapping);

  // è·å–é”®æ˜ å°„å…³ç³»
  Future<Map<String, String>> getKeyMapping();

  // ä¿å­˜è¿ç§»è®°å½•
  Future<void> saveMigrationRecord(MigrationRecord record);

  // è·å–è¿ç§»å†å²
  Future<List<MigrationRecord>> getMigrationHistory();
}
```

## ğŸ“¦ æ ¸å¿ƒç»„ä»¶è®¾è®¡

### 1. ç¼“å­˜é”®ç®¡ç†å™¨ (CacheKeyManager)

#### 1.1 æ¥å£å®šä¹‰
```dart
class CacheKeyConstants {
  // æ¨¡å—å¸¸é‡
  static const String MODULE_FUND = 'fund';
  static const String MODULE_PORTFOLIO = 'portfolio';
  static const String MODULE_SEARCH = 'search';
  static const String MODULE_USER = 'user';
  static const String MODULE_MARKET = 'market';

  // ç±»å‹å¸¸é‡
  static const String TYPE_DETAIL = 'detail';
  static const String TYPE_RANKING = 'ranking';
  static const String TYPE_COMPARISON = 'comparison';
  static const String TYPE_HOLDINGS = 'holdings';
  static const String TYPE_RESULTS = 'results';
  static const String TYPE_HISTORY = 'history';
  static const String TYPE_FAVORITES = 'favorites';
  static const String TYPE_PREFERENCES = 'preferences';

  // ç‰ˆæœ¬å¸¸é‡
  static const String VERSION_V1 = 'v1';
  static const String VERSION_V2 = 'v2';
}

class KeyComponents {
  final String module;
  final String type;
  final String identifier;
  final String version;

  const KeyComponents({
    required this.module,
    required this.type,
    required this.identifier,
    this.version = CacheKeyConstants.VERSION_V1,
  });

  @override
  String toString() => '$module:$type:$identifier:$version';
}
```

#### 1.2 å®ç°ç±»
```dart
class CacheKeyManagerImpl implements CacheKeyManager {
  final KeyValidator _validator;
  final ConflictDetector _conflictDetector;
  final KeyParser _parser;
  final CacheKeyRepository _repository;

  CacheKeyManagerImpl({
    required KeyValidator validator,
    required ConflictDetector conflictDetector,
    required KeyParser parser,
    required CacheKeyRepository repository,
  }) : _validator = validator,
       _conflictDetector = conflictDetector,
       _parser = parser,
       _repository = repository;

  @override
  String generateKey(String module, String type, String identifier, {String version = 'v1'}) {
    // è¾“å…¥éªŒè¯
    _validateInputs(module, type, identifier);

    // æ ¼å¼æ ‡å‡†åŒ–
    final normalizedModule = _normalizeModule(module);
    final normalizedType = _normalizeType(type);
    final normalizedIdentifier = _normalizeIdentifier(identifier);
    final normalizedVersion = _normalizeVersion(version);

    // ç”Ÿæˆé”®
    final key = '$normalizedModule:$normalizedType:$normalizedIdentifier:$normalizedVersion';

    // éªŒè¯ç”Ÿæˆçš„é”®
    if (!_validator.validate(key)) {
      throw CacheKeyException('Invalid cache key generated: $key');
    }

    return key;
  }

  @override
  bool validateKey(String key) {
    return _validator.validate(key);
  }

  @override
  KeyComponents parseKey(String key) {
    if (!_validator.validate(key)) {
      throw CacheKeyException('Invalid cache key format: $key');
    }

    return _parser.parse(key);
  }

  @override
  Future<List<KeyConflict>> detectConflicts(List<String> keys) async {
    return _conflictDetector.detect(keys);
  }

  @override
  List<String> generateBatchKeys(String module, String type, List<String> identifiers) {
    return identifiers
        .map((id) => generateKey(module, type, id))
        .toList();
  }

  // ç§æœ‰è¾…åŠ©æ–¹æ³•
  void _validateInputs(String module, String type, String identifier) {
    if (module.isEmpty) throw ArgumentError('Module cannot be empty');
    if (type.isEmpty) throw ArgumentError('Type cannot be empty');
    if (identifier.isEmpty) throw ArgumentError('Identifier cannot be empty');

    if (module.contains(':') || type.contains(':') || identifier.contains(':')) {
      throw ArgumentError('Inputs cannot contain colon character');
    }
  }

  String _normalizeModule(String module) {
    // æ ‡å‡†åŒ–æ¨¡å—åç§°
    final normalizedModules = {
      'fund': CacheKeyConstants.MODULE_FUND,
      'portfolio': CacheKeyConstants.MODULE_PORTFOLIO,
      'search': CacheKeyConstants.MODULE_SEARCH,
      'user': CacheKeyConstants.MODULE_USER,
      'market': CacheKeyConstants.MODULE_MARKET,
    };

    return normalizedModules[module.toLowerCase()] ?? module.toLowerCase();
  }

  String _normalizeType(String type) {
    // æ ‡å‡†åŒ–ç±»å‹åç§°
    final normalizedTypes = {
      'detail': CacheKeyConstants.TYPE_DETAIL,
      'ranking': CacheKeyConstants.TYPE_RANKING,
      'comparison': CacheKeyConstants.TYPE_COMPARISON,
      'holdings': CacheKeyConstants.TYPE_HOLDINGS,
      'results': CacheKeyConstants.TYPE_RESULTS,
      'history': CacheKeyConstants.TYPE_HISTORY,
      'favorites': CacheKeyConstants.TYPE_FAVORITES,
      'preferences': CacheKeyConstants.TYPE_PREFERENCES,
    };

    return normalizedTypes[type.toLowerCase()] ?? type.toLowerCase();
  }

  String _normalizeIdentifier(String identifier) {
    // æ¸…ç†å’Œæ ‡å‡†åŒ–æ ‡è¯†ç¬¦
    return identifier
        .toLowerCase()
        .replaceAll(RegExp(r'[^a-z0-9_-]'), '_')
        .replaceAll(RegExp(r'_+'), '_')
        .replaceAll(RegExp(r'^_|_$'), '');
  }

  String _normalizeVersion(String version) {
    // æ ‡å‡†åŒ–ç‰ˆæœ¬å·
    if (version.isEmpty) return CacheKeyConstants.VERSION_V1;
    return version.toLowerCase().startsWith('v') ? version : 'v$version';
  }
}
```

### 2. é”®éªŒè¯å™¨ (KeyValidator)

#### 2.1 éªŒè¯è§„åˆ™
```dart
class KeyValidator {
  static final RegExp _keyPattern = RegExp(r'^[a-z]+:[a-z]+:[a-z0-9_-]+:v[0-9]+$');
  static final int _maxKeyLength = 255;
  static final int _maxIdentifierLength = 100;

  bool validate(String key) {
    if (key.isEmpty) return false;
    if (key.length > _maxKeyLength) return false;

    // æ ¼å¼éªŒè¯
    if (!_keyPattern.hasMatch(key)) return false;

    // ç»„ä»¶éªŒè¯
    final components = key.split(':');
    if (components.length != 4) return false;

    final module = components[0];
    final type = components[1];
    final identifier = components[2];
    final version = components[3];

    return _validateModule(module) &&
           _validateType(type) &&
           _validateIdentifier(identifier) &&
           _validateVersion(version);
  }

  bool _validateModule(String module) {
    const validModules = [
      CacheKeyConstants.MODULE_FUND,
      CacheKeyConstants.MODULE_PORTFOLIO,
      CacheKeyConstants.MODULE_SEARCH,
      CacheKeyConstants.MODULE_USER,
      CacheKeyConstants.MODULE_MARKET,
    ];

    return validModules.contains(module);
  }

  bool _validateType(String type) {
    const validTypes = [
      CacheKeyConstants.TYPE_DETAIL,
      CacheKeyConstants.TYPE_RANKING,
      CacheKeyConstants.TYPE_COMPARISON,
      CacheKeyConstants.TYPE_HOLDINGS,
      CacheKeyConstants.TYPE_RESULTS,
      CacheKeyConstants.TYPE_HISTORY,
      CacheKeyConstants.TYPE_FAVORITES,
      CacheKeyConstants.TYPE_PREFERENCES,
    ];

    return validTypes.contains(type);
  }

  bool _validateIdentifier(String identifier) {
    if (identifier.isEmpty) return false;
    if (identifier.length > _maxIdentifierLength) return false;

    // æ ‡è¯†ç¬¦åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦
    return RegExp(r'^[a-z0-9_-]+$').hasMatch(identifier);
  }

  bool _validateVersion(String version) {
    return RegExp(r'^v[0-9]+$').hasMatch(version);
  }

  ValidationResult getValidationDetails(String key) {
    if (key.isEmpty) {
      return ValidationResult(false, 'Key cannot be empty');
    }

    if (key.length > _maxKeyLength) {
      return ValidationResult(false, 'Key length exceeds maximum limit of $_maxKeyLength');
    }

    if (!_keyPattern.hasMatch(key)) {
      return ValidationResult(false, 'Key format does not match required pattern: module:type:identifier:version');
    }

    final components = key.split(':');
    if (components.length != 4) {
      return ValidationResult(false, 'Key must have exactly 4 components separated by colons');
    }

    final module = components[0];
    final type = components[1];
    final identifier = components[2];
    final version = components[3];

    if (!_validateModule(module)) {
      return ValidationResult(false, 'Invalid module: $module');
    }

    if (!_validateType(type)) {
      return ValidationResult(false, 'Invalid type: $type');
    }

    if (!_validateIdentifier(identifier)) {
      return ValidationResult(false, 'Invalid identifier: $identifier');
    }

    if (!_validateVersion(version)) {
      return ValidationResult(false, 'Invalid version: $version');
    }

    return ValidationResult(true, 'Key is valid');
  }
}

class ValidationResult {
  final bool isValid;
  final String message;

  const ValidationResult(this.isValid, this.message);
}
```

### 3. é”®è§£æå™¨ (KeyParser)

```dart
class KeyParser {
  KeyComponents parse(String key) {
    final components = key.split(':');

    if (components.length != 4) {
      throw CacheKeyException('Invalid key format: expected 4 components, got ${components.length}');
    }

    return KeyComponents(
      module: components[0],
      type: components[1],
      identifier: components[2],
      version: components[3],
    );
  }

  Map<String, String> parseToMap(String key) {
    final components = parse(key);

    return {
      'module': components.module,
      'type': components.type,
      'identifier': components.identifier,
      'version': components.version,
      'full_key': key,
    };
  }

  String buildFromComponents(KeyComponents components) {
    return components.toString();
  }
}
```

## ğŸ”„ è¿ç§»å·¥å…·è®¾è®¡

### 1. è¿ç§»å¼•æ“ (MigrationEngine)

#### 1.1 æ¥å£å®šä¹‰
```dart
abstract class MigrationEngine {
  // æ‰§è¡Œé”®è¿ç§»
  Future<MigrationResult> migrateKeys(
    Map<String, String> keyMapping,
    {ProgressCallback? onProgress}
  );

  // éªŒè¯è¿ç§»ç»“æœ
  Future<ValidationResult> validateMigration();

  // å›æ»šè¿ç§»
  Future<void> rollbackMigration();

  // è·å–è¿ç§»çŠ¶æ€
  Future<MigrationStatus> getMigrationStatus();

  // æš‚åœ/æ¢å¤è¿ç§»
  Future<void> pauseMigration();
  Future<void> resumeMigration();
}

class MigrationResult {
  final bool success;
  final int totalKeys;
  final int migratedKeys;
  final int failedKeys;
  final List<MigrationError> errors;
  final Duration duration;

  const MigrationResult({
    required this.success,
    required this.totalKeys,
    required this.migratedKeys,
    required this.failedKeys,
    required this.errors,
    required this.duration,
  });

  double get successRate => totalKeys > 0 ? migratedKeys / totalKeys : 0.0;
}

class MigrationError {
  final String oldKey;
  final String newKey;
  final String error;
  final StackTrace? stackTrace;

  const MigrationError({
    required this.oldKey,
    required this.newKey,
    required this.error,
    this.stackTrace,
  });
}

enum MigrationStatus {
  notStarted,
  inProgress,
  paused,
  completed,
  failed,
  rolledBack,
}
```

#### 1.2 å®ç°ç±»
```dart
class MigrationEngineImpl implements MigrationEngine {
  final CacheKeyRepository _repository;
  final UnifiedHiveCacheManager _cacheManager;
  final ProgressTracker _progressTracker;
  final RollbackManager _rollbackManager;
  final Logger _logger;

  MigrationStatus _status = MigrationStatus.notStarted;
  bool _isPaused = false;

  MigrationEngineImpl({
    required CacheKeyRepository repository,
    required UnifiedHiveCacheManager cacheManager,
    required ProgressTracker progressTracker,
    required RollbackManager rollbackManager,
    required Logger logger,
  }) : _repository = repository,
       _cacheManager = cacheManager,
       _progressTracker = progressTracker,
       _rollbackManager = rollbackManager,
       _logger = logger;

  @override
  Future<MigrationResult> migrateKeys(
    Map<String, String> keyMapping,
    {ProgressCallback? onProgress}
  ) async {
    final stopwatch = Stopwatch()..start();
    _status = MigrationStatus.inProgress;

    try {
      _logger.info('Starting cache key migration with ${keyMapping.length} mappings');

      // åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ª
      await _progressTracker.initialize(keyMapping.length);

      // åˆ›å»ºå›æ»šå¤‡ä»½
      await _rollbackManager.createBackup(keyMapping.keys.toList());

      final totalKeys = keyMapping.length;
      int migratedKeys = 0;
      int failedKeys = 0;
      final errors = <MigrationError>[];

      // æ‰¹é‡è¿ç§»ç­–ç•¥
      const batchSize = 50;
      final batches = _createBatches(keyMapping, batchSize);

      for (int i = 0; i < batches.length; i++) {
        if (_isPaused) {
          _logger.info('Migration paused at batch ${i + 1}/${batches.length}');
          await _waitForResume();
        }

        final batch = batches[i];
        _logger.info('Processing batch ${i + 1}/${batches.length} with ${batch.length} keys');

        // æ‰§è¡Œæ‰¹é‡è¿ç§»
        final batchResult = await _migrateBatch(batch);

        migratedKeys += batchResult.migratedKeys;
        failedKeys += batchResult.failedKeys;
        errors.addAll(batchResult.errors);

        // æ›´æ–°è¿›åº¦
        await _progressTracker.updateProgress(migratedKeys);
        onProgress?.call(migratedKeys, totalKeys);

        // æ‰¹æ¬¡é—´çŸ­æš‚ä¼‘æ¯ï¼Œé¿å…ç³»ç»Ÿå‹åŠ›
        if (i < batches.length - 1) {
          await Future.delayed(Duration(milliseconds: 100));
        }
      }

      stopwatch.stop();

      final result = MigrationResult(
        success: failedKeys == 0,
        totalKeys: totalKeys,
        migratedKeys: migratedKeys,
        failedKeys: failedKeys,
        errors: errors,
        duration: stopwatch.elapsed,
      );

      if (result.success) {
        _status = MigrationStatus.completed;
        _logger.info('Migration completed successfully in ${stopwatch.elapsed}');

        // ä¿å­˜è¿ç§»è®°å½•
        await _saveMigrationRecord(result);
      } else {
        _status = MigrationStatus.failed;
        _logger.warning('Migration completed with $failedKeys failures');
      }

      return result;

    } catch (e, stackTrace) {
      stopwatch.stop();
      _status = MigrationStatus.failed;
      _logger.error('Migration failed: $e', stackTrace);

      // å°è¯•å›æ»š
      await _rollbackManager.rollback();

      rethrow;
    }
  }

  Future<BatchResult> _migrateBatch(Map<String, String> batch) async {
    int migratedKeys = 0;
    int failedKeys = 0;
    final errors = <MigrationError>[];

    for (final entry in batch.entries) {
      try {
        final oldKey = entry.key;
        final newKey = entry.value;

        // æ£€æŸ¥æ—§é”®æ˜¯å¦å­˜åœ¨
        final exists = await _cacheManager.containsKey(oldKey);
        if (!exists) {
          _logger.fine('Old key does not exist: $oldKey');
          migratedKeys++; // è§†ä¸ºæˆåŠŸï¼ˆæ— éœ€è¿ç§»ï¼‰
          continue;
        }

        // æ£€æŸ¥æ–°é”®æ˜¯å¦å·²å­˜åœ¨ï¼ˆå†²çªæ£€æµ‹ï¼‰
        final newKeyExists = await _cacheManager.containsKey(newKey);
        if (newKeyExists) {
          _logger.warning('New key already exists: $newKey');
          errors.add(MigrationError(
            oldKey: oldKey,
            newKey: newKey,
            error: 'Target key already exists',
          ));
          failedKeys++;
          continue;
        }

        // è·å–æ•°æ®
        final data = await _cacheManager.get(oldKey);
        if (data == null) {
          _logger.fine('No data found for key: $oldKey');
          migratedKeys++; // è§†ä¸ºæˆåŠŸ
          continue;
        }

        // è·å–å…ƒæ•°æ®
        final metadata = await _cacheManager.getMetadata(oldKey);

        // å­˜å‚¨åˆ°æ–°é”®
        await _cacheManager.put(newKey, data, metadata: metadata);

        // éªŒè¯è¿ç§»ç»“æœ
        final migratedData = await _cacheManager.get(newKey);
        if (migratedData == null) {
          throw CacheMigrationException('Failed to verify migrated data for key: $newKey');
        }

        // åˆ é™¤æ—§é”®ï¼ˆå»¶è¿Ÿåˆ é™¤ï¼Œç¡®ä¿è¿ç§»æˆåŠŸï¼‰
        await _cacheManager.delete(oldKey);

        migratedKeys++;
        _logger.fine('Successfully migrated key: $oldKey -> $newKey');

      } catch (e, stackTrace) {
        _logger.error('Failed to migrate key: ${entry.key}', stackTrace);
        errors.add(MigrationError(
          oldKey: entry.key,
          newKey: entry.value,
          error: e.toString(),
          stackTrace: stackTrace,
        ));
        failedKeys++;
      }
    }

    return BatchResult(
      migratedKeys: migratedKeys,
      failedKeys: failedKeys,
      errors: errors,
    );
  }

  List<Map<String, String>> _createBatches(Map<String, String> keyMapping, int batchSize) {
    final entries = keyMapping.entries.toList();
    final batches = <Map<String, String>>[];

    for (int i = 0; i < entries.length; i += batchSize) {
      final end = (i + batchSize < entries.length) ? i + batchSize : entries.length;
      final batch = Map<String, String>.fromEntries(
        entries.sublist(i, end)
      );
      batches.add(batch);
    }

    return batches;
  }

  Future<void> _waitForResume() async {
    while (_isPaused) {
      await Future.delayed(Duration(milliseconds: 100));
    }
  }

  Future<void> _saveMigrationRecord(MigrationResult result) async {
    final record = MigrationRecord(
      id: DateTime.now().millisecondsSinceEpoch.toString(),
      timestamp: DateTime.now(),
      result: result,
      status: _status,
    );

    await _repository.saveMigrationRecord(record);
  }

  @override
  Future<ValidationResult> validateMigration() async {
    // å®ç°è¿ç§»éªŒè¯é€»è¾‘
    // æ¯”è¾ƒè¿ç§»å‰åçš„æ•°æ®å®Œæ•´æ€§
    return ValidationResult(true, 'Migration validation completed successfully');
  }

  @override
  Future<void> rollbackMigration() async {
    _logger.info('Starting migration rollback');
    await _rollbackManager.rollback();
    _status = MigrationStatus.rolledBack;
    _logger.info('Migration rollback completed');
  }

  @override
  Future<MigrationStatus> getMigrationStatus() async {
    return _status;
  }

  @override
  Future<void> pauseMigration() async {
    _isPaused = true;
    _logger.info('Migration paused');
  }

  @override
  Future<void> resumeMigration() async {
    _isPaused = false;
    _logger.info('Migration resumed');
  }
}

class BatchResult {
  final int migratedKeys;
  final int failedKeys;
  final List<MigrationError> errors;

  const BatchResult({
    required this.migratedKeys,
    required this.failedKeys,
    required this.errors,
  });
}

typedef ProgressCallback = void Function(int completed, int total);
```

### 2. é”®æ˜ å°„å™¨ (KeyMapper)

```dart
class KeyMapper {
  static const Map<String, String> _predefinedMappings = {
    // åŸºé‡‘ç›¸å…³
    'fund_favorites': 'user:favorites:default',
    'fund_search_history': 'search:history:user',
    'fund_last_viewed': 'user:history:recently_viewed',
    'fund_detail_': 'fund:detail:',
    'fund_rankings_': 'fund:ranking:',
    'fund_comparison_': 'fund:comparison:',
    'filtered_results_': 'fund:filter:results:',

    // æœç´¢ç›¸å…³
    'search_results_': 'search:results:',
    'search_history_': 'search:history:',
    'search_suggestions_': 'search:suggestions:',
    'popular_searches': 'search:popular:default',

    // æŠ•èµ„ç»„åˆç›¸å…³
    'portfolio_holdings_': 'portfolio:holdings:',
    'nav_history_': 'portfolio:nav:history:',
    'profit_metrics_': 'portfolio:profit:metrics:',
    'benchmark_history_': 'portfolio:benchmark:history:',

    // ç”¨æˆ·åå¥½ç›¸å…³
    'fund_display_preferences': 'user:preferences:display',
    'fund_display_preferences_': 'user:preferences:display:',
    'theme_preferences': 'user:preferences:theme',
    'notification_settings': 'user:preferences:notifications',
  };

  Future<Map<String, String>> generateMigrationMapping() async {
    final mapping = <String, String>{};

    // æ·»åŠ é¢„å®šä¹‰æ˜ å°„
    mapping.addAll(_predefinedMappings);

    // æ‰«æç°æœ‰ç¼“å­˜é”®ï¼Œç”ŸæˆåŠ¨æ€æ˜ å°„
    final existingKeys = await _scanExistingKeys();
    final dynamicMappings = _generateDynamicMappings(existingKeys);
    mapping.addAll(dynamicMappings);

    return mapping;
  }

  Future<List<String>> _scanExistingKeys() async {
    // æ‰«ææ‰€æœ‰ç¼“å­˜ç³»ç»Ÿçš„é”®
    final allKeys = <String>[];

    // æ‰«æ UnifiedHiveCacheManager
    final unifiedKeys = await _scanUnifiedCache();
    allKeys.addAll(unifiedKeys);

    // æ‰«æ SharedPreferences
    final prefKeys = await _scanSharedPreferences();
    allKeys.addAll(prefKeys);

    // æ‰«æå…¶ä»–ç¼“å­˜ç³»ç»Ÿ
    final otherKeys = await _scanOtherCaches();
    allKeys.addAll(otherKeys);

    return allKeys.toSet().toList();
  }

  Future<List<String>> _scanUnifiedCache() async {
    // å®ç°ç»Ÿä¸€ç¼“å­˜æ‰«æé€»è¾‘
    return []; // å ä½ç¬¦å®ç°
  }

  Future<List<String>> _scanSharedPreferences() async {
    // å®ç° SharedPreferences æ‰«æé€»è¾‘
    return []; // å ä½ç¬¦å®ç°
  }

  Future<List<String>> _scanOtherCaches() async {
    // å®ç°å…¶ä»–ç¼“å­˜ç³»ç»Ÿæ‰«æé€»è¾‘
    return []; // å ä½ç¬¦å®ç°
  }

  Map<String, String> _generateDynamicMappings(List<String> existingKeys) {
    final mappings = <String, String>{};

    for (final key in existingKeys) {
      final newKey = _generateNewKey(key);
      if (newKey != null && newKey != key) {
        mappings[key] = newKey;
      }
    }

    return mappings;
  }

  String? _generateNewKey(String oldKey) {
    // åŸºäºæ—§é”®ç”Ÿæˆæ–°é”®çš„é€»è¾‘
    if (oldKey.startsWith('fund_detail_')) {
      final fundCode = oldKey.substring(12); // ç§»é™¤ 'fund_detail_' å‰ç¼€
      return 'fund:detail:$fundCode';
    }

    if (oldKey.startsWith('fund_rankings_')) {
      final identifier = oldKey.substring(13); // ç§»é™¤ 'fund_rankings_' å‰ç¼€
      return 'fund:ranking:$identifier';
    }

    if (oldKey.startsWith('search_results_')) {
      final query = oldKey.substring(14); // ç§»é™¤ 'search_results_' å‰ç¼€
      return 'search:results:$query';
    }

    // æ›´å¤šæ˜ å°„è§„åˆ™...

    return null; // æ— æ³•æ˜ å°„çš„é”®ä¿æŒä¸å˜
  }

  Future<String?> findConflictingKey(String newKey) async {
    // æ£€æŸ¥æ–°é”®æ˜¯å¦ä¸ç°æœ‰é”®å†²çª
    final existingKeys = await _scanExistingKeys();
    return existingKeys.firstWhereOrNull((key) => key == newKey);
  }
}
```

## ğŸ” å†²çªæ£€æµ‹å’Œè§£å†³æœºåˆ¶

### 1. å†²çªæ£€æµ‹å™¨ (ConflictDetector)

```dart
class ConflictDetector {
  final CacheKeyRepository _repository;
  final Logger _logger;

  ConflictDetector({
    required CacheKeyRepository repository,
    required Logger logger,
  }) : _repository = repository,
       _logger = logger;

  Future<List<KeyConflict>> detect(List<String> keys) async {
    final conflicts = <KeyConflict>[];

    _logger.info('Starting conflict detection for ${keys.length} keys');

    // æ£€æŸ¥æ ¼å¼å†²çª
    final formatConflicts = await _detectFormatConflicts(keys);
    conflicts.addAll(formatConflicts);

    // æ£€æŸ¥è¯­ä¹‰å†²çª
    final semanticConflicts = await _detectSemanticConflicts(keys);
    conflicts.addAll(semanticConflicts);

    // æ£€æŸ¥å‘½åå†²çª
    final namingConflicts = await _detectNamingConflicts(keys);
    conflicts.addAll(namingConflicts);

    _logger.info('Conflict detection completed: ${conflicts.length} conflicts found');

    return conflicts;
  }

  Future<List<KeyConflict>> _detectFormatConflicts(List<String> keys) async {
    final conflicts = <KeyConflict>[];
    final validator = KeyValidator();

    for (final key in keys) {
      final validation = validator.getValidationDetails(key);
      if (!validation.isValid) {
        conflicts.add(KeyConflict(
          type: ConflictType.format,
          key: key,
          description: validation.message,
          severity: ConflictSeverity.high,
        ));
      }
    }

    return conflicts;
  }

  Future<List<KeyConflict>> _detectSemanticConflicts(List<String> keys) async {
    final conflicts = <KeyConflict>[];
    final parser = KeyParser();

    // æ£€æŸ¥ç›¸åŒæ ‡è¯†ç¬¦çš„ä¸åŒç‰ˆæœ¬
    final identifierMap = <String, List<String>>{};

    for (final key in keys) {
      try {
        final components = parser.parse(key);
        final identifier = '${components.module}:${components.type}:${components.identifier}';

        identifierMap.putIfAbsent(identifier, () => []).add(key);
      } catch (e) {
        // å¿½ç•¥è§£æå¤±è´¥çš„é”®ï¼Œè¿™äº›å·²ç»è¢«æ ¼å¼æ£€æµ‹æ•è·
      }
    }

    // æŸ¥æ‰¾å…·æœ‰å¤šä¸ªç‰ˆæœ¬çš„æ ‡è¯†ç¬¦
    for (final entry in identifierMap.entries) {
      if (entry.value.length > 1) {
        conflicts.add(KeyConflict(
          type: ConflictType.version,
          key: entry.value.join(', '),
          description: 'Multiple versions found for identifier: ${entry.key}',
          severity: ConflictSeverity.medium,
          suggestions: _generateVersionResolutionSuggestions(entry.value),
        ));
      }
    }

    return conflicts;
  }

  Future<List<KeyConflict>> _detectNamingConflicts(List<String> keys) async {
    final conflicts = <KeyConflict>[];

    // æ£€æŸ¥é‡å¤é”®
    final keySet = <String>{};
    for (final key in keys) {
      if (keySet.contains(key)) {
        conflicts.add(KeyConflict(
          type: ConflictType.duplicate,
          key: key,
          description: 'Duplicate key found',
          severity: ConflictSeverity.high,
        ));
      } else {
        keySet.add(key);
      }
    }

    // æ£€æŸ¥ç›¸ä¼¼çš„é”®ï¼ˆå¯èƒ½çš„æ‹¼å†™é”™è¯¯ï¼‰
    final similarKeys = _findSimilarKeys(keys);
    for (final pair in similarKeys) {
      conflicts.add(KeyConflict(
        type: ConflictType.similarity,
        key: '${pair.item1} / ${pair.item2}',
        description: 'Similar keys detected, possible typo',
        severity: ConflictSeverity.low,
      ));
    }

    return conflicts;
  }

  List<Tuple2<String, String>> _findSimilarKeys(List<String> keys) {
    final similarKeys = <Tuple2<String, String>>[];
    const similarityThreshold = 0.8;

    for (int i = 0; i < keys.length; i++) {
      for (int j = i + 1; j < keys.length; j++) {
        final similarity = _calculateSimilarity(keys[i], keys[j]);
        if (similarity >= similarityThreshold) {
          similarKeys.add(Tuple2(keys[i], keys[j]));
        }
      }
    }

    return similarKeys;
  }

  double _calculateSimilarity(String s1, String s2) {
    // ä½¿ç”¨ Levenshtein è·ç¦»è®¡ç®—ç›¸ä¼¼åº¦
    final distance = _levenshteinDistance(s1, s2);
    final maxLength = math.max(s1.length, s2.length);
    return 1.0 - (distance / maxLength);
  }

  int _levenshteinDistance(String s1, String s2) {
    final matrix = List<List<int>>.generate(
      s1.length + 1,
      (i) => List<int>.generate(s2.length + 1, (j) => j),
    );

    for (int i = 1; i <= s1.length; i++) {
      matrix[i][0] = i;
      for (int j = 1; j <= s2.length; j++) {
        final cost = s1[i - 1] == s2[j - 1] ? 0 : 1;
        matrix[i][j] = math.min(
          math.min(matrix[i - 1][j] + 1, matrix[i][j - 1] + 1),
          matrix[i - 1][j - 1] + cost,
        );
      }
    }

    return matrix[s1.length][s2.length];
  }

  List<String> _generateVersionResolutionSuggestions(List<String> conflictingKeys) {
    final suggestions = <String>[];

    // å»ºè®®1ï¼šä¿ç•™æœ€æ–°ç‰ˆæœ¬
    suggestions.add('Keep the latest version and remove older versions');

    // å»ºè®®2ï¼šåˆå¹¶ç‰ˆæœ¬æ•°æ®
    suggestions.add('Merge data from all versions into the latest version');

    // å»ºè®®3ï¼šä¿ç•™æ‰€æœ‰ç‰ˆæœ¬ä½†æ·»åŠ æ—¶é—´æˆ³
    suggestions.add('Keep all versions but add timestamps to differentiate');

    return suggestions;
  }
}

class KeyConflict {
  final ConflictType type;
  final String key;
  final String description;
  final ConflictSeverity severity;
  final List<String> suggestions;

  const KeyConflict({
    required this.type,
    required this.key,
    required this.description,
    required this.severity,
    this.suggestions = const [],
  });

  @override
  String toString() {
    return 'KeyConflict(type: $type, key: $key, description: $description, severity: $severity)';
  }
}

enum ConflictType {
  format,      // æ ¼å¼é”™è¯¯
  duplicate,   // é‡å¤é”®
  version,     // ç‰ˆæœ¬å†²çª
  similarity,  // ç›¸ä¼¼é”®
}

enum ConflictSeverity {
  low,         // ä½ä¼˜å…ˆçº§
  medium,      // ä¸­ç­‰ä¼˜å…ˆçº§
  high,        // é«˜ä¼˜å…ˆçº§
  critical,    // ä¸¥é‡å†²çª
}
```

## ğŸ“Š è¿›åº¦è·Ÿè¸ªå’Œå›æ»šæœºåˆ¶

### 1. è¿›åº¦è·Ÿè¸ªå™¨ (ProgressTracker)

```dart
class ProgressTracker {
  final CacheKeyRepository _repository;
  final Logger _logger;

  int _totalItems = 0;
  int _completedItems = 0;
  int _failedItems = 0;
  DateTime? _startTime;
  DateTime? _endTime;
  List<ProgressSnapshot> _snapshots = [];

  ProgressTracker({
    required CacheKeyRepository repository,
    required Logger logger,
  }) : _repository = repository,
       _logger = logger;

  Future<void> initialize(int totalItems) async {
    _totalItems = totalItems;
    _completedItems = 0;
    _failedItems = 0;
    _startTime = DateTime.now();
    _endTime = null;
    _snapshots.clear();

    _logger.info('Progress tracker initialized with $totalItems items');

    // ä¿å­˜åˆå§‹çŠ¶æ€
    await _saveProgress();
  }

  Future<void> updateProgress(int completedItems) async {
    _completedItems = completedItems;
    _failedItems = _calculateFailedItems();

    // åˆ›å»ºè¿›åº¦å¿«ç…§
    final snapshot = ProgressSnapshot(
      timestamp: DateTime.now(),
      completedItems: _completedItems,
      failedItems: _failedItems,
      totalItems: _totalItems,
      percentage: _calculatePercentage(),
      estimatedTimeRemaining: _estimateTimeRemaining(),
    );

    _snapshots.add(snapshot);

    // å®šæœŸä¿å­˜è¿›åº¦
    if (_snapshots.length % 10 == 0) {
      await _saveProgress();
    }

    _logger.fine('Progress updated: ${snapshot.percentage.toStringAsFixed(1)}%');
  }

  ProgressReport getCurrentProgress() {
    return ProgressReport(
      totalItems: _totalItems,
      completedItems: _completedItems,
      failedItems: _failedItems,
      percentage: _calculatePercentage(),
      startTime: _startTime,
      endTime: _endTime,
      estimatedTimeRemaining: _estimateTimeRemaining(),
      isCompleted: _completedItems >= _totalItems,
      snapshots: List.unmodifiable(_snapshots),
    );
  }

  double _calculatePercentage() {
    if (_totalItems == 0) return 0.0;
    return (_completedItems / _totalItems) * 100;
  }

  int _calculateFailedItems() {
    // åŸºäºé”™è¯¯æ—¥å¿—æˆ–å¤±è´¥è®¡æ•°å™¨è®¡ç®—å¤±è´¥é¡¹ç›®æ•°
    return 0; // å ä½ç¬¦å®ç°
  }

  Duration? _estimateTimeRemaining() {
    if (_startTime == null || _completedItems == 0) return null;

    final elapsed = DateTime.now().difference(_startTime!);
    final itemsPerSecond = _completedItems / elapsed.inSeconds;
    final remainingItems = _totalItems - _completedItems;

    if (itemsPerSecond <= 0) return null;

    final remainingSeconds = remainingItems / itemsPerSecond;
    return Duration(seconds: remainingSeconds.round());
  }

  Future<void> complete() async {
    _endTime = DateTime.now();
    await _saveProgress();
    _logger.info('Progress tracking completed');
  }

  Future<void> _saveProgress() async {
    final progress = getCurrentProgress();
    await _repository.saveMigrationProgress(progress);
  }

  Future<void> loadProgress() async {
    final savedProgress = await _repository.getMigrationProgress();
    if (savedProgress != null) {
      _totalItems = savedProgress.totalItems;
      _completedItems = savedProgress.completedItems;
      _failedItems = savedProgress.failedItems;
      _startTime = savedProgress.startTime;
      _endTime = savedProgress.endTime;
      _snapshots = List.from(savedProgress.snapshots);
    }
  }
}

class ProgressSnapshot {
  final DateTime timestamp;
  final int completedItems;
  final int failedItems;
  final int totalItems;
  final double percentage;
  final Duration? estimatedTimeRemaining;

  const ProgressSnapshot({
    required this.timestamp,
    required this.completedItems,
    required this.failedItems,
    required this.totalItems,
    required this.percentage,
    this.estimatedTimeRemaining,
  });
}

class ProgressReport {
  final int totalItems;
  final int completedItems;
  final int failedItems;
  final double percentage;
  final DateTime? startTime;
  final DateTime? endTime;
  final Duration? estimatedTimeRemaining;
  final bool isCompleted;
  final List<ProgressSnapshot> snapshots;

  const ProgressReport({
    required this.totalItems,
    required this.completedItems,
    required this.failedItems,
    required this.percentage,
    this.startTime,
    this.endTime,
    this.estimatedTimeRemaining,
    required this.isCompleted,
    required this.snapshots,
  });

  Duration? get totalDuration {
    if (startTime == null) return null;
    final end = endTime ?? DateTime.now();
    return end.difference(startTime!);
  }
}
```

### 2. å›æ»šç®¡ç†å™¨ (RollbackManager)

```dart
class RollbackManager {
  final CacheKeyRepository _repository;
  final UnifiedHiveCacheManager _cacheManager;
  final Logger _logger;

  BackupData? _currentBackup;

  RollbackManager({
    required CacheKeyRepository repository,
    required UnifiedHiveCacheManager cacheManager,
    required Logger logger,
  }) : _repository = repository,
       _cacheManager = cacheManager,
       _logger = logger;

  Future<void> createBackup(List<String> keysToMigrate) async {
    _logger.info('Creating backup for ${keysToMigrate.length} keys');

    final backupData = <String, BackupItem>{};
    final startTime = DateTime.now();

    for (final key in keysToMigrate) {
      try {
        // å¤‡ä»½åŸå§‹æ•°æ®
        final data = await _cacheManager.get(key);
        final metadata = await _cacheManager.getMetadata(key);

        if (data != null) {
          backupData[key] = BackupItem(
            originalKey: key,
            data: data,
            metadata: metadata,
            timestamp: DateTime.now(),
          );
        }

      } catch (e, stackTrace) {
        _logger.warning('Failed to backup key: $key', stackTrace);
        // ç»§ç»­å¤„ç†å…¶ä»–é”®ï¼Œä¸è®©å•ä¸ªå¤‡ä»½å¤±è´¥å½±å“æ•´ä¸ªè¿‡ç¨‹
      }
    }

    _currentBackup = BackupData(
      id: DateTime.now().millisecondsSinceEpoch.toString(),
      timestamp: startTime,
      keys: keysToMigrate,
      backupItems: backupData,
      duration: DateTime.now().difference(startTime),
    );

    // ä¿å­˜å¤‡ä»½åˆ°æŒä¹…åŒ–å­˜å‚¨
    await _saveBackup();

    _logger.info('Backup created successfully: ${backupData.length} items backed up');
  }

  Future<void> rollback() async {
    if (_currentBackup == null) {
      throw CacheMigrationException('No backup available for rollback');
    }

    _logger.info('Starting rollback process for backup: ${_currentBackup!.id}');

    try {
      await _loadBackup(); // ç¡®ä¿ä½¿ç”¨æœ€æ–°çš„å¤‡ä»½æ•°æ®

      final backup = _currentBackup!;
      int restoredKeys = 0;
      int failedRestores = 0;

      // æ¢å¤æ•°æ®
      for (final entry in backup.backupItems.entries) {
        try {
          final key = entry.key;
          final backupItem = entry.value;

          // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ é™¤è¿ç§»åçš„é”®
          await _cleanupMigratedKeys(key);

          // æ¢å¤åŸå§‹æ•°æ®
          await _cacheManager.put(
            key,
            backupItem.data,
            metadata: backupItem.metadata,
          );

          restoredKeys++;

        } catch (e, stackTrace) {
          _logger.error('Failed to restore key: ${entry.key}', stackTrace);
          failedRestores++;
        }
      }

      _logger.info('Rollback completed: $restoredKeys restored, $failedRestores failed');

      if (failedRestores > 0) {
        _logger.warning('Rollback completed with $failedRestores failures');
      }

    } catch (e, stackTrace) {
      _logger.error('Rollback failed: $e', stackTrace);
      rethrow;
    }
  }

  Future<void> _cleanupMigratedKeys(String originalKey) async {
    // æŸ¥æ‰¾å¹¶åˆ é™¤å¯èƒ½å·²è¿ç§»çš„é”®
    final mapper = KeyMapper();
    final migrationMapping = await mapper.generateMigrationMapping();

    final migratedKey = migrationMapping[originalKey];
    if (migratedKey != null && migratedKey != originalKey) {
      try {
        final exists = await _cacheManager.containsKey(migratedKey);
        if (exists) {
          await _cacheManager.delete(migratedKey);
          _logger.fine('Deleted migrated key: $migratedKey');
        }
      } catch (e) {
        _logger.warning('Failed to delete migrated key: $migratedKey', e);
      }
    }
  }

  Future<void> _saveBackup() async {
    if (_currentBackup != null) {
      await _repository.saveBackupData(_currentBackup!);
    }
  }

  Future<void> _loadBackup() async {
    final latestBackup = await _repository.getLatestBackupData();
    if (latestBackup != null) {
      _currentBackup = latestBackup;
    }
  }

  Future<void> cleanupBackup() async {
    if (_currentBackup != null) {
      await _repository.deleteBackupData(_currentBackup!.id);
      _currentBackup = null;
      _logger.info('Backup cleaned up successfully');
    }
  }

  BackupInfo? getBackupInfo() {
    if (_currentBackup == null) return null;

    return BackupInfo(
      id: _currentBackup!.id,
      timestamp: _currentBackup!.timestamp,
      keyCount: _currentBackup!.keys.length,
      itemCount: _currentBackup!.backupItems.length,
      duration: _currentBackup!.duration,
    );
  }
}

class BackupData {
  final String id;
  final DateTime timestamp;
  final List<String> keys;
  final Map<String, BackupItem> backupItems;
  final Duration duration;

  const BackupData({
    required this.id,
    required this.timestamp,
    required this.keys,
    required this.backupItems,
    required this.duration,
  });
}

class BackupItem {
  final String originalKey;
  final dynamic data;
  final CacheMetadata? metadata;
  final DateTime timestamp;

  const BackupItem({
    required this.originalKey,
    required this.data,
    this.metadata,
    required this.timestamp,
  });
}

class BackupInfo {
  final String id;
  final DateTime timestamp;
  final int keyCount;
  final int itemCount;
  final Duration duration;

  const BackupInfo({
    required this.id,
    required this.timestamp,
    required this.keyCount,
    required this.itemCount,
    required this.duration,
  });
}
```

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

#### 1.1 ç¼“å­˜é”®ç®¡ç†å™¨æµ‹è¯•
```dart
// test/unit/core/cache/key_management/cache_key_manager_test.dart
void main() {
  group('CacheKeyManager', () {
    late CacheKeyManager manager;
    late MockKeyValidator mockValidator;
    late MockConflictDetector mockConflictDetector;
    late MockKeyParser mockParser;
    late MockCacheKeyRepository mockRepository;

    setUp(() {
      mockValidator = MockKeyValidator();
      mockConflictDetector = MockConflictDetector();
      mockParser = MockKeyParser();
      mockRepository = MockCacheKeyRepository();

      manager = CacheKeyManagerImpl(
        validator: mockValidator,
        conflictDetector: mockConflictDetector,
        parser: mockParser,
        repository: mockRepository,
      );
    });

    test('should generate valid cache key', () {
      // Arrange
      when(mockValidator.validate(any)).thenReturn(true);

      // Act
      final key = manager.generateKey('fund', 'detail', '000001');

      // Assert
      expect(key, equals('fund:detail:000001:v1'));
      verify(mockValidator.validate(key)).called(1);
    });

    test('should throw exception for invalid inputs', () {
      // Act & Assert
      expect(
        () => manager.generateKey('', 'detail', '000001'),
        throwsArgumentError,
      );

      expect(
        () => manager.generateKey('fund', '', '000001'),
        throwsArgumentError,
      );

      expect(
        () => manager.generateKey('fund', 'detail', ''),
        throwsArgumentError,
      );
    });

    test('should validate cache key format', () {
      // Arrange
      const validKey = 'fund:detail:000001:v1';
      const invalidKey = 'invalid_key';

      when(mockValidator.validate(validKey)).thenReturn(true);
      when(mockValidator.validate(invalidKey)).thenReturn(false);

      // Act & Assert
      expect(manager.validateKey(validKey), isTrue);
      expect(manager.validateKey(invalidKey), isFalse);
    });

    test('should parse cache key components', () {
      // Arrange
      const key = 'fund:detail:000001:v1';
      final expectedComponents = KeyComponents(
        module: 'fund',
        type: 'detail',
        identifier: '000001',
        version: 'v1',
      );

      when(mockValidator.validate(key)).thenReturn(true);
      when(mockParser.parse(key)).thenReturn(expectedComponents);

      // Act
      final components = manager.parseKey(key);

      // Assert
      expect(components, equals(expectedComponents));
      verify(mockValidator.validate(key)).called(1);
      verify(mockParser.parse(key)).called(1);
    });

    test('should generate batch keys', () {
      // Arrange
      when(mockValidator.validate(any)).thenReturn(true);
      final identifiers = ['000001', '000002', '000003'];

      // Act
      final keys = manager.generateBatchKeys('fund', 'detail', identifiers);

      // Assert
      expect(keys, hasLength(3));
      expect(keys[0], equals('fund:detail:000001:v1'));
      expect(keys[1], equals('fund:detail:000002:v1'));
      expect(keys[2], equals('fund:detail:000003:v1'));
    });
  });
}
```

#### 1.2 é”®éªŒè¯å™¨æµ‹è¯•
```dart
// test/unit/core/cache/key_management/key_validator_test.dart
void main() {
  group('KeyValidator', () {
    late KeyValidator validator;

    setUp(() {
      validator = KeyValidator();
    });

    test('should validate correct key format', () {
      const validKeys = [
        'fund:detail:000001:v1',
        'user:favorites:default:v1',
        'search:results:tech_funds:v2',
        'portfolio:holdings:user123:v1',
      ];

      for (final key in validKeys) {
        expect(validator.validate(key), isTrue, reason: 'Key should be valid: $key');
      }
    });

    test('should reject invalid key format', () {
      const invalidKeys = [
        '',                           // ç©ºé”®
        'invalid_key',               // æ— æ ¼å¼
        'fund:detail:000001',        // ç¼ºå°‘ç‰ˆæœ¬
        'fund:detail:v1',            // ç¼ºå°‘æ ‡è¯†ç¬¦
        'fund:v1',                   // ç¼ºå°‘ç±»å‹å’Œæ ‡è¯†ç¬¦
        'Fund:Detail:000001:v1',     // å¤§å†™å­—æ¯
        'fund:detail:000001:V1',     // ç‰ˆæœ¬å·å¤§å†™
        'fund:detail:Invalid:Name:v1', // åŒ…å«æ— æ•ˆå­—ç¬¦
        'a:detail:identifier:v1',    // æ¨¡å—åå¤ªçŸ­
      ];

      for (final key in invalidKeys) {
        expect(validator.validate(key), isFalse, reason: 'Key should be invalid: $key');
      }
    });

    test('should provide detailed validation feedback', () {
      // Test empty key
      var result = validator.getValidationDetails('');
      expect(result.isValid, isFalse);
      expect(result.message, contains('empty'));

      // Test key that exceeds maximum length
      final longKey = 'fund:detail:${'a' * 300}:v1';
      result = validator.getValidationDetails(longKey);
      expect(result.isValid, isFalse);
      expect(result.message, contains('length'));

      // Test valid key
      const validKey = 'fund:detail:000001:v1';
      result = validator.getValidationDetails(validKey);
      expect(result.isValid, isTrue);
      expect(result.message, contains('valid'));
    });

    test('should validate module names', () {
      const validModules = ['fund', 'portfolio', 'search', 'user', 'market'];
      const invalidModules = ['invalid', 'test', 'module'];

      for (final module in validModules) {
        final key = '$module:detail:000001:v1';
        expect(validator.validate(key), isTrue, reason: 'Module should be valid: $module');
      }

      for (final module in invalidModules) {
        final key = '$module:detail:000001:v1';
        expect(validator.validate(key), isFalse, reason: 'Module should be invalid: $module');
      }
    });
  });
}
```

### 2. é›†æˆæµ‹è¯•

```dart
// test/integration/cache_migration_integration_test.dart
void main() {
  group('Cache Migration Integration Tests', () {
    late CacheKeyManager keyManager;
    late MigrationEngine migrationEngine;
    late KeyMapper keyMapper;
    late ConflictDetector conflictDetector;
    late TestHiveHelper hiveHelper;

    setUp(() async {
      // åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ
      hiveHelper = TestHiveHelper();
      await hiveHelper.setUp();

      // åˆå§‹åŒ–ç»„ä»¶
      final repository = MockCacheKeyRepository();
      final cacheManager = UnifiedHiveCacheManager();
      final progressTracker = ProgressTracker(
        repository: repository,
        logger: MockLogger(),
      );
      final rollbackManager = RollbackManager(
        repository: repository,
        cacheManager: cacheManager,
        logger: MockLogger(),
      );

      keyManager = CacheKeyManagerImpl(
        validator: KeyValidator(),
        conflictDetector: ConflictDetector(
          repository: repository,
          logger: MockLogger(),
        ),
        parser: KeyParser(),
        repository: repository,
      );

      migrationEngine = MigrationEngineImpl(
        repository: repository,
        cacheManager: cacheManager,
        progressTracker: progressTracker,
        rollbackManager: rollbackManager,
        logger: MockLogger(),
      );

      keyMapper = KeyMapper();
      conflictDetector = ConflictDetector(
        repository: repository,
        logger: MockLogger(),
      );
    });

    tearDown(() async {
      await hiveHelper.tearDown();
    });

    test('should perform complete migration workflow', () async {
      // Arrange - åˆ›å»ºæµ‹è¯•æ•°æ®
      final testData = {
        'fund_favorites': ['000001', '000002', '000003'],
        'fund_detail_000001': {'name': 'Test Fund 1', 'code': '000001'},
        'fund_detail_000002': {'name': 'Test Fund 2', 'code': '000002'},
        'search_results_tech': ['000001', '000002'],
      };

      await _createTestData(testData);

      // Act - æ‰§è¡Œè¿ç§»
      final migrationMapping = await keyMapper.generateMigrationMapping();
      final result = await migrationEngine.migrateKeys(migrationMapping);

      // Assert - éªŒè¯è¿ç§»ç»“æœ
      expect(result.success, isTrue);
      expect(result.migratedKeys, greaterThan(0));
      expect(result.failedKeys, equals(0));

      // éªŒè¯æ–°é”®å­˜åœ¨
      expect(await cacheManager.containsKey('user:favorites:default'), isTrue);
      expect(await cacheManager.containsKey('fund:detail:000001'), isTrue);
      expect(await cacheManager.containsKey('search:results:tech'), isTrue);

      // éªŒè¯æ—§é”®ä¸å­˜åœ¨
      expect(await cacheManager.containsKey('fund_favorites'), isFalse);
      expect(await cacheManager.containsKey('fund_detail_000001'), isFalse);

      // éªŒè¯æ•°æ®å®Œæ•´æ€§
      final favorites = await cacheManager.get('user:favorites:default');
      expect(favorites, equals(['000001', '000002', '000003']));

      final fundDetail = await cacheManager.get('fund:detail:000001');
      expect(fundDetail['name'], equals('Test Fund 1'));
    });

    test('should detect and handle conflicts', () async {
      // Arrange - åˆ›å»ºå†²çªæ•°æ®
      await cacheManager.put('user:favorites:default', ['000001']);
      await cacheManager.put('fund_favorites', ['000002']);

      final keys = ['user:favorites:default', 'fund_favorites'];

      // Act - æ£€æµ‹å†²çª
      final conflicts = await conflictDetector.detect(keys);

      // Assert - éªŒè¯å†²çªæ£€æµ‹
      expect(conflicts, isNotEmpty);
      final conflict = conflicts.firstWhere(
        (c) => c.type == ConflictType.duplicate,
        orElse: () => throw Exception('Expected duplicate conflict not found'),
      );

      expect(conflict.severity, equals(ConflictSeverity.high));
    });

    test('should rollback on migration failure', () async {
      // Arrange - åˆ›å»ºæµ‹è¯•æ•°æ®
      await cacheManager.put('fund_favorites', ['000001']);

      // æ¨¡æ‹Ÿè¿ç§»å¤±è´¥
      final migrationMapping = {'fund_favorites': 'user:favorites:default'};

      // Act & Assert - æ‰§è¡Œè¿ç§»å¹¶éªŒè¯å›æ»š
      expect(
        () => migrationEngine.migrateKeys(migrationMapping),
        throwsA(isA<CacheMigrationException>()),
      );

      // éªŒè¯æ•°æ®å·²å›æ»š
      expect(await cacheManager.containsKey('fund_favorites'), isTrue);
      expect(await cacheManager.containsKey('user:favorites:default'), isFalse);
    });

    test('should maintain data integrity during migration', () async {
      // Arrange - åˆ›å»ºå¤æ‚æ•°æ®ç»“æ„
      final complexData = {
        'portfolio_holdings_user1': {
          'funds': [
            {'code': '000001', 'shares': 1000, 'cost': 1.23},
            {'code': '000002', 'shares': 500, 'cost': 2.45},
          ],
          'timestamp': DateTime.now().toIso8601String(),
          'version': '1.0',
        }
      };

      await _createTestData(complexData);

      // Act - æ‰§è¡Œè¿ç§»
      final migrationMapping = await keyMapper.generateMigrationMapping();
      final result = await migrationEngine.migrateKeys(migrationMapping);

      // Assert - éªŒè¯æ•°æ®å®Œæ•´æ€§
      expect(result.success, isTrue);

      final migratedData = await cacheManager.get('portfolio:holdings:user1');
      expect(migratedData, isNotNull);
      expect(migratedData['funds'], hasLength(2));
      expect(migratedData['funds'][0]['code'], equals('000001'));
      expect(migratedData['funds'][0]['shares'], equals(1000));
    });
  });

  Future<void> _createTestData(Map<String, dynamic> data) async {
    for (final entry in data.entries) {
      await cacheManager.put(entry.key, entry.value);
    }
  }
}
```

### 3. æ€§èƒ½æµ‹è¯•

```dart
// test/performance/cache_migration_performance_test.dart
void main() {
  group('Cache Migration Performance Tests', () {
    late CacheKeyManager keyManager;
    late MigrationEngine migrationEngine;

    setUp(() async {
      // åˆå§‹åŒ–æ€§èƒ½æµ‹è¯•ç¯å¢ƒ
      await _setupPerformanceTestEnvironment();
    });

    test('should migrate 10,000 keys within acceptable time', () async {
      // Arrange - åˆ›å»ºå¤§é‡æµ‹è¯•æ•°æ®
      const keyCount = 10000;
      final testData = _generateLargeTestData(keyCount);
      await _createTestData(testData);

      // Act - æ‰§è¡Œè¿ç§»å¹¶æµ‹é‡æ€§èƒ½
      final stopwatch = Stopwatch()..start();

      final migrationMapping = await keyMapper.generateMigrationMapping();
      final mappingTime = stopwatch.elapsed;

      stopwatch.reset();
      final result = await migrationEngine.migrateKeys(migrationMapping);
      final migrationTime = stopwatch.elapsed;

      // Assert - éªŒè¯æ€§èƒ½æŒ‡æ ‡
      expect(result.success, isTrue);
      expect(result.migratedKeys, equals(keyCount));

      // æ€§èƒ½æ–­è¨€
      expect(mappingTime.inSeconds, lessThan(5)); // æ˜ å°„ç”Ÿæˆ < 5ç§’
      expect(migrationTime.inSeconds, lessThan(30)); // è¿ç§»æ‰§è¡Œ < 30ç§’

      // è®¡ç®—ååé‡
      final throughput = keyCount / migrationTime.inSeconds;
      expect(throughput, greaterThan(300)); // > 300 é”®/ç§’

      print('Performance Results:');
      print('  Key Count: $keyCount');
      print('  Mapping Time: ${mappingTime.inMilliseconds}ms');
      print('  Migration Time: ${migrationTime.inMilliseconds}ms');
      print('  Throughput: ${throughput.toStringAsFixed(2)} keys/second');
    });

    test('should handle memory efficiently during migration', () async {
      // Arrange - åˆ›å»ºå†…å­˜å¯†é›†å‹æµ‹è¯•æ•°æ®
      final largeData = _generateMemoryIntensiveData();
      await _createTestData(largeData);

      // Act - ç›‘æ§å†…å­˜ä½¿ç”¨
      final initialMemory = _getCurrentMemoryUsage();

      final migrationMapping = await keyMapper.generateMigrationMapping();
      final afterMappingMemory = _getCurrentMemoryUsage();

      final result = await migrationEngine.migrateKeys(migrationMapping);
      final finalMemory = _getCurrentMemoryUsage();

      // Assert - éªŒè¯å†…å­˜ä½¿ç”¨æ•ˆç‡
      final memoryIncreaseDuringMapping = afterMappingMemory - initialMemory;
      final memoryIncreaseDuringMigration = finalMemory - afterMappingMemory;

      // å†…å­˜å¢é•¿åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
      expect(memoryIncreaseDuringMapping, lessThan(100 * 1024 * 1024)); // < 100MB
      expect(memoryIncreaseDuringMigration, lessThan(200 * 1024 * 1024)); // < 200MB

      print('Memory Usage Results:');
      print('  Initial Memory: ${(initialMemory / 1024 / 1024).toStringAsFixed(2)} MB');
      print('  After Mapping: ${(afterMappingMemory / 1024 / 1024).toStringAsFixed(2)} MB');
      print('  Final Memory: ${(finalMemory / 1024 / 1024).toStringAsFixed(2)} MB');
    });

    test('should maintain performance under concurrent load', () async {
      // Arrange - åˆ›å»ºå¹¶å‘æµ‹è¯•
      const concurrentOperations = 10;
      final futures = <Future<MigrationResult>>[];

      // Act - æ‰§è¡Œå¹¶å‘è¿ç§»
      for (int i = 0; i < concurrentOperations; i++) {
        final testData = _generateTestDataForConcurrency(i);
        await _createTestData(testData);

        futures.add(migrationEngine.migrateKeys(
          await keyMapper.generateMigrationMapping(),
        ));
      }

      final results = await Future.wait(futures);

      // Assert - éªŒè¯å¹¶å‘æ€§èƒ½
      expect(results, hasLength(concurrentOperations));
      expect(results.every((r) => r.success), isTrue);

      final totalMigrated = results.fold<int>(0, (sum, r) => sum + r.migratedKeys);
      expect(totalMigrated, greaterThan(0));

      print('Concurrency Results:');
      print('  Concurrent Operations: $concurrentOperations');
      print('  Total Keys Migrated: $totalMigrated');
      print('  Average per Operation: ${totalMigrated / concurrentOperations}');
    });
  });
}
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. æ‰¹å¤„ç†ä¼˜åŒ–

```dart
class BatchOptimizationStrategy {
  static const int DEFAULT_BATCH_SIZE = 50;
  static const int MAX_BATCH_SIZE = 200;
  static const int MIN_BATCH_SIZE = 10;

  static int calculateOptimalBatchSize(
    int totalItems,
    int availableMemoryMB,
    int processingCores,
  ) {
    // åŸºäºå†…å­˜å®¹é‡è®¡ç®—æ‰¹æ¬¡å¤§å°
    int memoryBasedSize = (availableMemoryMB * 0.1).round();
    memoryBasedSize = memoryBasedSize.clamp(MIN_BATCH_SIZE, MAX_BATCH_SIZE);

    // åŸºäºCPUæ ¸å¿ƒæ•°è®¡ç®—æ‰¹æ¬¡å¤§å°
    int cpuBasedSize = processingCores * 25;
    cpuBasedSize = cpuBasedSize.clamp(MIN_BATCH_SIZE, MAX_BATCH_SIZE);

    // åŸºäºæ€»æ•°æ®é‡è°ƒæ•´
    int dataBasedSize = totalItems < 1000 ? MIN_BATCH_SIZE :
                       totalItems < 10000 ? DEFAULT_BATCH_SIZE :
                       MAX_BATCH_SIZE;

    // ç»¼åˆè€ƒè™‘æ‰€æœ‰å› ç´ 
    final optimalSize = [memoryBasedSize, cpuBasedSize, dataBasedSize].reduce((a, b) => math.min(a, b));

    return optimalSize.clamp(MIN_BATCH_SIZE, MAX_BATCH_SIZE);
  }

  static Duration calculateOptimalDelay(int batchSize, int processingTimeMs) {
    // åŸºäºå¤„ç†æ—¶é—´è®¡ç®—æ‰¹æ¬¡é—´å»¶è¿Ÿ
    if (processingTimeMs < 100) return Duration.zero; // å¿«é€Ÿå¤„ç†æ— éœ€å»¶è¿Ÿ
    if (processingTimeMs < 500) return Duration(milliseconds: 10); // ä¸­ç­‰å¤„ç†çŸ­æš‚å»¶è¿Ÿ
    return Duration(milliseconds: 50); // æ…¢é€Ÿå¤„ç†è¾ƒé•¿å»¶è¿Ÿ
  }
}
```

### 2. å†…å­˜ä¼˜åŒ–

```dart
class MemoryOptimizationManager {
  static const int MEMORY_THRESHOLD_MB = 512;
  static const int CRITICAL_MEMORY_THRESHOLD_MB = 768;

  Timer? _memoryMonitorTimer;
  final List<MemoryPressureCallback> _callbacks = [];

  void startMonitoring() {
    _memoryMonitorTimer = Timer.periodic(Duration(seconds: 5), (_) {
      _checkMemoryPressure();
    });
  }

  void stopMonitoring() {
    _memoryMonitorTimer?.cancel();
    _memoryMonitorTimer = null;
  }

  void addMemoryPressureCallback(MemoryPressureCallback callback) {
    _callbacks.add(callback);
  }

  void _checkMemoryPressure() {
    final currentMemory = _getCurrentMemoryUsage();
    final memoryMB = currentMemory / 1024 / 1024;

    if (memoryMB > CRITICAL_MEMORY_THRESHOLD_MB) {
      _handleCriticalMemoryPressure();
    } else if (memoryMB > MEMORY_THRESHOLD_MB) {
      _handleModerateMemoryPressure();
    }
  }

  void _handleCriticalMemoryPressure() {
    _logger.warning('Critical memory pressure detected');

    // è§¦å‘åƒåœ¾å›æ”¶
    _triggerGarbageCollection();

    // é€šçŸ¥æ‰€æœ‰å›è°ƒ
    for (final callback in _callbacks) {
      callback(MemoryPressureLevel.critical);
    }

    // å¼ºåˆ¶æ¸…ç†ç¼“å­˜
    _clearNonEssentialCaches();
  }

  void _handleModerateMemoryPressure() {
    _logger.info('Moderate memory pressure detected');

    // é€šçŸ¥æ‰€æœ‰å›è°ƒ
    for (final callback in _callbacks) {
      callback(MemoryPressureLevel.moderate);
    }

    // è½»åº¦æ¸…ç†
    _clearOldCacheData();
  }

  void _triggerGarbageCollection() {
    // åœ¨ Dart ä¸­è°ƒç”¨åƒåœ¾å›æ”¶
    // æ³¨æ„ï¼šè¿™ä¸æ˜¯ä¸€ä¸ªæ¨èçš„å®è·µï¼Œä»…ç”¨äºæç«¯æƒ…å†µ
  }

  void _clearNonEssentialCaches() {
    // æ¸…ç†éå¿…è¦ç¼“å­˜
  }

  void _clearOldCacheData() {
    // æ¸…ç†è¿‡æœŸç¼“å­˜æ•°æ®
  }

  int _getCurrentMemoryUsage() {
    // è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡
    return 0; // å ä½ç¬¦å®ç°
  }
}

typedef MemoryPressureCallback = void Function(MemoryPressureLevel level);

enum MemoryPressureLevel {
  normal,
  moderate,
  critical,
}
```

## ğŸ“‹ éƒ¨ç½²å’Œç›‘æ§

### 1. éƒ¨ç½²æ£€æŸ¥æ¸…å•

```dart
class DeploymentValidator {
  final List<ValidationCheck> _preDeploymentChecks = [
    ValidationCheck(
      name: 'Cache Backup Verification',
      description: 'Verify that all cache data is properly backed up',
      validator: _verifyCacheBackup,
      severity: CheckSeverity.critical,
    ),
    ValidationCheck(
      name: 'Memory Availability Check',
      description: 'Ensure sufficient memory is available for migration',
      validator: _checkMemoryAvailability,
      severity: CheckSeverity.high,
    ),
    ValidationCheck(
      name: 'Disk Space Verification',
      description: 'Verify sufficient disk space for migration data',
      validator: _checkDiskSpace,
      severity: CheckSeverity.high,
    ),
    ValidationCheck(
      name: 'Dependency Compatibility',
      description: 'Check all dependencies are compatible with new cache system',
      validator: _checkDependencyCompatibility,
      severity: CheckSeverity.medium,
    ),
  ];

  Future<DeploymentValidationResult> validateDeployment() async {
    final results = <ValidationResult>[];

    for (final check in _preDeploymentChecks) {
      try {
        final result = await check.validator();
        results.add(result);

        if (!result.passed && check.severity == CheckSeverity.critical) {
          return DeploymentValidationResult(
            canDeploy: false,
            results: results,
            blockingIssue: 'Critical check failed: ${check.name}',
          );
        }
      } catch (e, stackTrace) {
        _logger.error('Validation check failed: ${check.name}', stackTrace);
        results.add(ValidationResult(
          checkName: check.name,
          passed: false,
          message: 'Check execution failed: $e',
        ));
      }
    }

    final canDeploy = results.every((r) => r.passed) ||
                     results.where((r) => !r.passed).every((r) =>
                        _preDeploymentChecks.firstWhere((c) => c.name == r.checkName).severity != CheckSeverity.critical);

    return DeploymentValidationResult(
      canDeploy: canDeploy,
      results: results,
    );
  }

  static Future<ValidationResult> _verifyCacheBackup() async {
    // å®ç°ç¼“å­˜å¤‡ä»½éªŒè¯é€»è¾‘
    return ValidationResult(checkName: 'Cache Backup Verification', passed: true);
  }

  static Future<ValidationResult> _checkMemoryAvailability() async {
    // å®ç°å†…å­˜å¯ç”¨æ€§æ£€æŸ¥
    return ValidationResult(checkName: 'Memory Availability Check', passed: true);
  }

  static Future<ValidationResult> _checkDiskSpace() async {
    // å®ç°ç£ç›˜ç©ºé—´æ£€æŸ¥
    return ValidationResult(checkName: 'Disk Space Verification', passed: true);
  }

  static Future<ValidationResult> _checkDependencyCompatibility() async {
    // å®ç°ä¾èµ–å…¼å®¹æ€§æ£€æŸ¥
    return ValidationResult(checkName: 'Dependency Compatibility', passed: true);
  }
}

class ValidationCheck {
  final String name;
  final String description;
  final Future<ValidationResult> Function() validator;
  final CheckSeverity severity;

  const ValidationCheck({
    required this.name,
    required this.description,
    required this.validator,
    required this.severity,
  });
}

class ValidationResult {
  final String checkName;
  final bool passed;
  final String? message;

  const ValidationResult({
    required this.checkName,
    required this.passed,
    this.message,
  });
}

class DeploymentValidationResult {
  final bool canDeploy;
  final List<ValidationResult> results;
  final String? blockingIssue;

  const DeploymentValidationResult({
    required this.canDeploy,
    required this.results,
    this.blockingIssue,
  });
}

enum CheckSeverity {
  low,
  medium,
  high,
  critical,
}
```

### 2. ç›‘æ§å’Œå‘Šè­¦

```dart
class CacheMigrationMonitor {
  final MetricsCollector _metricsCollector;
  final AlertManager _alertManager;
  final Logger _logger;

  CacheMigrationMonitor({
    required MetricsCollector metricsCollector,
    required AlertManager alertManager,
    required Logger logger,
  }) : _metricsCollector = metricsCollector,
       _alertManager = alertManager,
       _logger = logger;

  void startMonitoring() {
    // ç›‘æ§è¿ç§»è¿›åº¦
    _monitorProgress();

    // ç›‘æ§æ€§èƒ½æŒ‡æ ‡
    _monitorPerformance();

    // ç›‘æ§é”™è¯¯ç‡
    _monitorErrorRate();

    // ç›‘æ§ç³»ç»Ÿèµ„æº
    _monitorSystemResources();
  }

  void _monitorProgress() {
    Timer.periodic(Duration(seconds: 10), (_) {
      final progress = _getCurrentProgress();
      _metricsCollector.recordMetric('migration_progress_percentage', progress.percentage);

      // æ£€æŸ¥è¿›åº¦åœæ»
      if (_isProgressStalled(progress)) {
        _alertManager.sendAlert(
          AlertType.progressStalled,
          'Migration progress appears to be stalled',
          severity: AlertSeverity.warning,
        );
      }
    });
  }

  void _monitorPerformance() {
    Timer.periodic(Duration(seconds: 30), (_) {
      final metrics = _collectPerformanceMetrics();

      _metricsCollector.recordMetric('migration_throughput', metrics.throughput);
      _metricsCollector.recordMetric('memory_usage_mb', metrics.memoryUsageMB);
      _metricsCollector.recordMetric('cpu_usage_percentage', metrics.cpuUsagePercentage);

      // æ£€æŸ¥æ€§èƒ½å¼‚å¸¸
      if (metrics.throughput < _getExpectedThroughput() * 0.5) {
        _alertManager.sendAlert(
          AlertType.performanceDegradation,
          'Migration throughput is below expected threshold',
          severity: AlertSeverity.warning,
        );
      }

      if (metrics.memoryUsageMB > MEMORY_THRESHOLD_MB) {
        _alertManager.sendAlert(
          AlertType.highMemoryUsage,
          'Memory usage is above threshold',
          severity: AlertSeverity.critical,
        );
      }
    });
  }

  void _monitorErrorRate() {
    Timer.periodic(Duration(seconds: 15), (_) {
      final errorRate = _calculateErrorRate();
      _metricsCollector.recordMetric('error_rate_percentage', errorRate);

      if (errorRate > ERROR_RATE_THRESHOLD) {
        _alertManager.sendAlert(
          AlertType.highErrorRate,
          'Error rate is above threshold: ${errorRate.toStringAsFixed(2)}%',
          severity: AlertSeverity.critical,
        );
      }
    });
  }

  void _monitorSystemResources() {
    Timer.periodic(Duration(minutes: 1), (_) {
      final systemMetrics = _collectSystemMetrics();

      _metricsCollector.recordMetric('disk_usage_percentage', systemMetrics.diskUsagePercentage);
      _metricsCollector.recordMetric('network_io_bytes', systemMetrics.networkIOBytes);

      if (systemMetrics.diskUsagePercentage > DISK_USAGE_THRESHOLD) {
        _alertManager.sendAlert(
          AlertType.lowDiskSpace,
          'Disk usage is above threshold',
          severity: AlertSeverity.warning,
        );
      }
    });
  }

  ProgressReport _getCurrentProgress() {
    // è·å–å½“å‰è¿ç§»è¿›åº¦
    return ProgressReport(
      totalItems: 0,
      completedItems: 0,
      failedItems: 0,
      percentage: 0.0,
      isCompleted: false,
      snapshots: [],
    );
  }

  bool _isProgressStalled(ProgressReport progress) {
    // æ£€æŸ¥è¿›åº¦æ˜¯å¦åœæ»
    return false; // å ä½ç¬¦å®ç°
  }

  PerformanceMetrics _collectPerformanceMetrics() {
    // æ”¶é›†æ€§èƒ½æŒ‡æ ‡
    return PerformanceMetrics(
      throughput: 0.0,
      memoryUsageMB: 0,
      cpuUsagePercentage: 0.0,
    );
  }

  double _getExpectedThroughput() {
    // è·å–é¢„æœŸååé‡
    return 300.0; // é”®/ç§’
  }

  double _calculateErrorRate() {
    // è®¡ç®—é”™è¯¯ç‡
    return 0.0;
  }

  SystemMetrics _collectSystemMetrics() {
    // æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
    return SystemMetrics(
      diskUsagePercentage: 0.0,
      networkIOBytes: 0,
    );
  }
}

class PerformanceMetrics {
  final double throughput; // é”®/ç§’
  final int memoryUsageMB;
  final double cpuUsagePercentage;

  const PerformanceMetrics({
    required this.throughput,
    required this.memoryUsageMB,
    required this.cpuUsagePercentage,
  });
}

class SystemMetrics {
  final double diskUsagePercentage;
  final int networkIOBytes;

  const SystemMetrics({
    required this.diskUsagePercentage,
    required this.networkIOBytes,
  });
}

enum AlertType {
  progressStalled,
  performanceDegradation,
  highMemoryUsage,
  highErrorRate,
  lowDiskSpace,
}

enum AlertSeverity {
  info,
  warning,
  critical,
}
```

## ğŸ“š æ–‡æ¡£å’Œç»´æŠ¤

### 1. API æ–‡æ¡£

```dart
/// ç¼“å­˜é”®ç®¡ç†å™¨
///
/// æä¾›ç»Ÿä¸€çš„ç¼“å­˜é”®ç”Ÿæˆã€éªŒè¯ã€è§£æå’Œç®¡ç†åŠŸèƒ½ã€‚
///
/// ä½¿ç”¨ç¤ºä¾‹ï¼š
/// ```dart
/// final manager = CacheKeyManagerImpl();
///
/// // ç”Ÿæˆç¼“å­˜é”®
/// final key = manager.generateKey('fund', 'detail', '000001');
/// print(key); // è¾“å‡º: fund:detail:000001:v1
///
/// // éªŒè¯ç¼“å­˜é”®
/// final isValid = manager.validateKey('fund:detail:000001:v1');
///
/// // è§£æç¼“å­˜é”®
/// final components = manager.parseKey('fund:detail:000001:v1');
/// print(components.module); // è¾“å‡º: fund
/// ```
///
/// æ³¨æ„äº‹é¡¹ï¼š
/// - æ‰€æœ‰ç»„ä»¶å‚æ•°éƒ½åº”è¯¥æ˜¯å°å†™å­—æ¯
/// - æ ‡è¯†ç¬¦åªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦
/// - ç‰ˆæœ¬å·æ ¼å¼ä¸º 'v' + æ•°å­—ï¼Œä¾‹å¦‚ 'v1', 'v2'
class CacheKeyManager {
  /// ç”Ÿæˆæ ‡å‡†æ ¼å¼çš„ç¼“å­˜é”®
  ///
  /// [module] æ¨¡å—åç§°ï¼Œå¿…é¡»æ˜¯é¢„å®šä¹‰çš„æ¨¡å—å¸¸é‡ä¹‹ä¸€
  /// [type] ç±»å‹åç§°ï¼Œå¿…é¡»æ˜¯é¢„å®šä¹‰çš„ç±»å‹å¸¸é‡ä¹‹ä¸€
  /// [identifier] æ ‡è¯†ç¬¦ï¼Œç”¨äºå”¯ä¸€æ ‡è¯†ç¼“å­˜é¡¹
  /// [version] ç‰ˆæœ¬å·ï¼Œé»˜è®¤ä¸º 'v1'
  ///
  /// è¿”å›æ ¼å¼ä¸º `module:type:identifier:version` çš„ç¼“å­˜é”®
  ///
  /// æŠ›å‡º [ArgumentError] å½“è¾“å…¥å‚æ•°æ— æ•ˆæ—¶
  /// æŠ›å‡º [CacheKeyException] å½“ç”Ÿæˆçš„é”®æ ¼å¼æ— æ•ˆæ—¶
  String generateKey(String module, String type, String identifier, {String version = 'v1'});

  /// éªŒè¯ç¼“å­˜é”®æ ¼å¼æ˜¯å¦æ­£ç¡®
  ///
  /// [key] è¦éªŒè¯çš„ç¼“å­˜é”®
  ///
  /// è¿”å› `true` å¦‚æœé”®æ ¼å¼æ­£ç¡®ï¼Œå¦åˆ™è¿”å› `false`
  bool validateKey(String key);

  /// è§£æç¼“å­˜é”®çš„å„ä¸ªç»„ä»¶
  ///
  /// [key] è¦è§£æçš„ç¼“å­˜é”®
  ///
  /// è¿”å›åŒ…å«æ¨¡å—ã€ç±»å‹ã€æ ‡è¯†ç¬¦å’Œç‰ˆæœ¬ä¿¡æ¯çš„ [KeyComponents] å¯¹è±¡
  ///
  /// æŠ›å‡º [CacheKeyException] å½“é”®æ ¼å¼æ— æ•ˆæ—¶
  KeyComponents parseKey(String key);

  /// æ£€æµ‹ä¸€ç»„é”®ä¸­çš„å†²çª
  ///
  /// [keys] è¦æ£€æµ‹å†²çªçš„é”®åˆ—è¡¨
  ///
  /// è¿”å›æ£€æµ‹åˆ°çš„å†²çªåˆ—è¡¨
  Future<List<KeyConflict>> detectConflicts(List<String> keys);

  /// æ‰¹é‡ç”Ÿæˆç¼“å­˜é”®
  ///
  /// [module] æ¨¡å—åç§°
  /// [type] ç±»å‹åç§°
  /// [identifiers] æ ‡è¯†ç¬¦åˆ—è¡¨
  ///
  /// è¿”å›ç”Ÿæˆçš„ç¼“å­˜é”®åˆ—è¡¨
  List<String> generateBatchKeys(String module, String type, List<String> identifiers);
}
```

### 2. æ•…éšœæ’é™¤æŒ‡å—

```markdown
# ç¼“å­˜é”®è¿ç§»æ•…éšœæ’é™¤æŒ‡å—

## å¸¸è§é—®é¢˜

### 1. è¿ç§»è¿‡ç¨‹ä¸­å‡ºç°å†…å­˜ä¸è¶³é”™è¯¯

**ç—‡çŠ¶**: è¿ç§»è¿‡ç¨‹ä¸­æ”¶åˆ° `OutOfMemoryError` æˆ–ç³»ç»Ÿå˜å¾—éå¸¸ç¼“æ…¢

**è§£å†³æ–¹æ¡ˆ**:
1. å‡å°æ‰¹æ¬¡å¤§å°ï¼šå°† `DEFAULT_BATCH_SIZE` ä» 50 å‡å°åˆ° 20
2. å¢åŠ æ‰¹æ¬¡é—´å»¶è¿Ÿï¼šè®¾ç½® `batchDelay` ä¸º `Duration(milliseconds: 200)`
3. å¯ç”¨å†…å­˜ç›‘æ§ï¼šç¡®ä¿ `MemoryOptimizationManager` æ­£åœ¨è¿è¡Œ
4. å…³é—­å…¶ä»–åº”ç”¨ç¨‹åºé‡Šæ”¾å†…å­˜

**é¢„é˜²æªæ–½**:
- åœ¨è¿ç§»å‰è¯„ä¼°æ•°æ®é‡å¤§å°
- ç¡®ä¿ç³»ç»Ÿæœ‰è¶³å¤Ÿçš„å¯ç”¨å†…å­˜ï¼ˆå»ºè®®è‡³å°‘ 2GB å¯ç”¨å†…å­˜ï¼‰

### 2. è¿ç§»é€Ÿåº¦è¿‡æ…¢

**ç—‡çŠ¶**: è¿ç§»è¿›åº¦ç¼“æ…¢ï¼Œååé‡ä½äºé¢„æœŸ

**è¯Šæ–­æ­¥éª¤**:
1. æ£€æŸ¥ CPU ä½¿ç”¨ç‡
2. ç›‘æ§ç£ç›˜ I/O
3. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆå¦‚æœæ¶‰åŠè¿œç¨‹ç¼“å­˜ï¼‰
4. æŸ¥çœ‹é”™è¯¯æ—¥å¿—

**è§£å†³æ–¹æ¡ˆ**:
1. å¢åŠ æ‰¹æ¬¡å¤§å°ï¼ˆå¦‚æœå†…å­˜å…è®¸ï¼‰
2. å‡å°‘æ‰¹æ¬¡é—´å»¶è¿Ÿ
3. å¯ç”¨å¹¶è¡Œå¤„ç†
4. æ£€æŸ¥å­˜å‚¨æ€§èƒ½

### 3. è¿ç§»åæ•°æ®ä¸ä¸€è‡´

**ç—‡çŠ¶**: è¿ç§»å®Œæˆåçš„æ•°æ®ä¸åŸå§‹æ•°æ®ä¸åŒ¹é…

**è¯Šæ–­æ­¥éª¤**:
1. æ£€æŸ¥è¿ç§»æ—¥å¿—ä¸­çš„é”™è¯¯è®°å½•
2. è¿è¡Œæ•°æ®å®Œæ•´æ€§éªŒè¯
3. æ¯”å¯¹è¿ç§»å‰åçš„æ•°æ®å“ˆå¸Œå€¼
4. æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®æˆªæ–­æˆ–æ ¼å¼è½¬æ¢é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**:
1. ä½¿ç”¨å¤‡ä»½è¿›è¡Œå›æ»š
2. é‡æ–°è¿è¡Œè¿ç§»ï¼Œè¿™æ¬¡å¯ç”¨è¯¦ç»†æ—¥å¿—
3. æ‰‹åŠ¨ä¿®å¤ä¸ä¸€è‡´çš„æ•°æ®
4. æ›´æ–°è¿ç§»æ˜ å°„è§„åˆ™

### 4. å†²çªæ£€æµ‹æŠ¥å‘Šè¿‡å¤šé—®é¢˜

**ç—‡çŠ¶**: å†²çªæ£€æµ‹è¿”å›å¤§é‡å†²çªï¼Œé˜»æ­¢è¿ç§»è¿›è¡Œ

**è§£å†³æ–¹æ¡ˆ**:
1. ä¼˜å…ˆå¤„ç†é«˜ä¸¥é‡æ€§å†²çª
2. æ£€æŸ¥æ˜¯å¦æ˜¯è¯¯æŠ¥
3. æ›´æ–°å†²çªæ£€æµ‹è§„åˆ™
4. æ‰‹åŠ¨è§£å†³å¤æ‚å†²çª

## è°ƒè¯•å·¥å…·

### 1. è¿ç§»è°ƒè¯•æ¨¡å¼

```dart
// å¯ç”¨è¯¦ç»†æ—¥å¿—
Logger.root.level = Level.FINE;

// å¯ç”¨è°ƒè¯•æ¨¡å¼
final migrationEngine = MigrationEngineImpl(
  // ... å…¶ä»–å‚æ•°
  debugMode: true,
);

// è¿è¡Œå°æ‰¹é‡æµ‹è¯•
final testKeys = ['fund_favorites', 'fund_detail_000001'];
final testResult = await migrationEngine.migrateKeys(
  testMapping,
  onProgress: (completed, total) {
    print('Progress: $completed/$total');
  },
);
```

### 2. æ•°æ®éªŒè¯å·¥å…·

```dart
// éªŒè¯æ•°æ®å®Œæ•´æ€§
final validator = DataIntegrityValidator();
final report = await validator.validateMigration();
print(report.summary);

// ç”Ÿæˆæ•°æ®å“ˆå¸Œ
final hasher = DataHasher();
final beforeHash = await hasher.calculateHash('old_key');
final afterHash = await hasher.calculateHash('new_key');
print('Hash match: ${beforeHash == afterHash}');
```

## æ€§èƒ½è°ƒä¼˜

### 1. æ‰¹æ¬¡å¤§å°ä¼˜åŒ–

| æ•°æ®é‡ | æ¨èæ‰¹æ¬¡å¤§å° | æ‰¹æ¬¡é—´å»¶è¿Ÿ |
|--------|-------------|-----------|
| < 1,000 é”® | 50 | 50ms |
| 1,000-10,000 é”® | 100 | 100ms |
| > 10,000 é”® | 200 | 200ms |

### 2. å†…å­˜ä¼˜åŒ–å»ºè®®

- ç¡®ä¿è‡³å°‘ 1GB å¯ç”¨å†…å­˜
- å¯ç”¨å†…å­˜å‹åŠ›ç›‘æ§
- å®šæœŸè§¦å‘åƒåœ¾å›æ”¶
- ä½¿ç”¨æµå¼å¤„ç†å¤§æ•°æ®é›†

## ç›‘æ§æŒ‡æ ‡

### å…³é”®æŒ‡æ ‡

1. **è¿ç§»ååé‡**: é”®/ç§’ï¼Œåº”è¯¥ > 300
2. **å†…å­˜ä½¿ç”¨ç‡**: åº”è¯¥ < 80%
3. **é”™è¯¯ç‡**: åº”è¯¥ < 1%
4. **CPU ä½¿ç”¨ç‡**: åº”è¯¥ < 90%

### å‘Šè­¦é˜ˆå€¼

- ååé‡ < 100 é”®/ç§’ï¼šè­¦å‘Š
- å†…å­˜ä½¿ç”¨ç‡ > 90%ï¼šä¸¥é‡
- é”™è¯¯ç‡ > 5%ï¼šä¸¥é‡
- è¿ç§»åœæ» > 5 åˆ†é’Ÿï¼šè­¦å‘Š
```

## ğŸ“‹ å®æ–½æ—¶é—´è¡¨

### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€è®¾æ–½ (3-4 å¤©)
- [x] è®¾è®¡ç¼“å­˜é”®ç®¡ç†å™¨æ¥å£
- [x] å®ç°é”®éªŒè¯å™¨å’Œè§£æå™¨
- [x] åˆ›å»ºæ ¸å¿ƒæ•°æ®æ¨¡å‹
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•æ¡†æ¶
- [ ] è®¾ç½® CI/CD é›†æˆ

### ç¬¬äºŒé˜¶æ®µï¼šè¿ç§»å·¥å…· (4-5 å¤©)
- [ ] å®ç°è¿ç§»å¼•æ“æ ¸å¿ƒé€»è¾‘
- [ ] å¼€å‘é”®æ˜ å°„å™¨
- [ ] åˆ›å»ºå†²çªæ£€æµ‹å™¨
- [ ] å®ç°è¿›åº¦è·Ÿè¸ªå™¨
- [ ] å»ºç«‹å›æ»šæœºåˆ¶

### ç¬¬ä¸‰é˜¶æ®µï¼šé›†æˆå’Œæµ‹è¯• (3-4 å¤©)
- [ ] é›†æˆåˆ°ç°æœ‰ç¼“å­˜ç³»ç»Ÿ
- [ ] æ‰§è¡Œé›†æˆæµ‹è¯•
- [ ] æ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–
- [ ] ç¼–å†™é›†æˆæ–‡æ¡£

### ç¬¬å››é˜¶æ®µï¼šéƒ¨ç½²å’Œç›‘æ§ (2-3 å¤©)
- [ ] åˆ›å»ºéƒ¨ç½²è„šæœ¬
- [ ] è®¾ç½®ç›‘æ§å’Œå‘Šè­¦
- [ ] ç¼–å†™æ“ä½œæ‰‹å†Œ
- [ ] æ‰§è¡Œç”Ÿäº§ç¯å¢ƒè¿ç§»

**æ€»è®¡**: 12-16 å¤©

## ğŸ¯ æˆåŠŸæ ‡å‡†

### åŠŸèƒ½æ€§æ ‡å‡†
- âœ… æ‰€æœ‰ç°æœ‰ç¼“å­˜é”®æˆåŠŸè¿ç§»
- âœ… é›¶æ•°æ®ä¸¢å¤±
- âœ… æ–°é”®å‘½åè§„èŒƒ 100% éµå¾ª
- âœ… å†²çªæ£€æµ‹å’Œè§£å†³æœºåˆ¶æ­£å¸¸å·¥ä½œ

### æ€§èƒ½æ ‡å‡†
- âœ… ç¼“å­˜é”®æŸ¥æ‰¾æ•ˆç‡æå‡ â‰¥ 20%
- âœ… è¿ç§»ååé‡ â‰¥ 300 é”®/ç§’
- âœ… å†…å­˜ä½¿ç”¨ä¼˜åŒ– â‰¥ 15%
- âœ… è¿ç§»å®Œæˆåæ€§èƒ½ä¸ä½äºåŸæœ‰æ°´å¹³

### è´¨é‡æ ‡å‡†
- âœ… å•å…ƒæµ‹è¯•è¦†ç›–ç‡ â‰¥ 90%
- âœ… é›†æˆæµ‹è¯•é€šè¿‡ç‡ 100%
- âœ… ä»£ç å®¡æŸ¥é€šè¿‡
- âœ… æ–‡æ¡£å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2025-10-29
**å®¡æ ¸çŠ¶æ€**: å¾…å®¡æ ¸
**å®æ–½è´Ÿè´£äºº**: ç³»ç»Ÿæ¶æ„å¸ˆ
**æŠ€æœ¯è´Ÿè´£äºº**: ç¼“å­˜ç³»ç»Ÿå›¢é˜Ÿ